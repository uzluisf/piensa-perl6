


\chapter{Regexes y Gramáticas}
\label{regex_grammars}
\index{regex}
\index{regular expression}
\index{grammar}

Las expresiones regulares o regexes fueron introducidas en las
Secciones~\ref{regex} a \ref{substitutions}. Es recomendable que leas
esas secciones nuevamente antes de leer este capítulo si no 
recuerdas mucho sobre los regexes. No necesitas recordar los detalles
de todo lo que discutimos anteriormente y explicaremos de nuevo, aunque
brevemente, las partes específicas de la funcionalidad que usaremos,
pero se espera que entiendas cómo los regexes funcionan en general.

\section{Una Breve Actualización}

\index{pattern}
Los regexes, como los estudiamos hasta ahora, tratan sobre
la exploración de cadenas de texto usando patrones. 
Un patrón es una secuencia de caracteres (usualmente especiales)
que describen una cadena de texto o parte de una 
cadena de texto. Un patrón coincide con una cadena de texto si existe
una correspondencia entre el patrón y la cadena de texto.

Por ejemplo, el siguiente fragmento de código inspecciona la 
cadena de texto y trata de encontrar la letra ``a``, seguida por 
cualquier número (pero por lo menos una) de letras ``b`` o ``c``,
seguida por cero o más dígitos seguidos por una ``B`` o una ``C``:

\begin{verbatim}
my $cad = "foo13abbccbcbcbb42Cbar";
say ~$/ if $cad ~~ /a <[bc]>+ (\d*) [B|C]/;  # -> abbccbcbcbb42C
say ~$0;                                     # -> 42
\end{verbatim}

\index{smart match operator}
\index{operator!smart match}
Este fragmento de código usa el operador de coincidencia 
inteligente \verb|~~| para chequear si la cadena \verb|$cad|
coincide con el patrón \verb'/a <[bc]>+ (\d*) [B|C]/'. Recuerda
que los espacios en blanco no son usualmente significativos en 
un patrón de regex (a menos que se especifiquen).
\index{pattern}

El patrón está compuesto por los siguientes componentes:

\begin{itemize}

\item \verb'a': una coincidencia literal de la letra ``a''

\index{character class}
\item \verb'<[bc]>+': el átomo \verb'<[bc]>' es una categoría de caracteres
que se refiere a la letra ``b`` o ``c``; el cuantificador \verb|+|
dicta que los caracteres que coinciden con la categoría de caracteres
``b`` o ``c`` pueden repetirse una o más veces.

\index{quantifier}
\index{capture!regex}
\item \verb'(\d*)': el átomo \verb|\d| es una categoría de caracteres
que son dígitos, el cuantificador \verb|*| significa 0 o más ocurrencias
del átomo anterior, y los paréntesis requieren una captura
de estos dígitos (si existen) en la variable \verb|$0| (una variable especial
que es realmente un atajo para \verb|$/[0]|)


\index{alternation}
\item \verb'[B|C]': \verb'B|C' es una alternación (una ``B`` o un ``C``),
y los corchetes reagrupan esta alternación en un (y también habilita 
precedencia adecuada).
\index{subpattern}

\end{itemize}

\index{match object}
Si la coincidencia es exitosa (como en este ejemplo), 
el resultado se almacena en el \emph{objeto de coincidencia},
\verb|$/|. La impresión de \verb|~$/| muestra una versión en
cadena de texto del objeto de coincidencia. Y la impresión de \verb|$0|
(o \verb|$/[0]|) muestra la captura (la porción de la coincidencia
entre los paréntesis, en este caso el número ``42``).
\index{capture}
\index{regex!capture}
\index{match object}

\index{lexing}
\index{parsing}
\index{lexical analysis}
\index{grammatical analysis}
Esto es lo que se llama coincidencia a un bajo nivel:
el reconocimiento del patrón se hace mayormente al nivel
individual de un carácter. Perl~6 ofrece varias maneras de 
agrupar y nombrar los patrones de regex para que estos
patrones individuales puedan utilizarse posteriormente 
como componentes básicos para coincidencia a un alto nivel:
el reconocimiento de palabras y secuencias de palabras (más
que caracteres), para el propósito de hacer lo que se conoce
como análisis léxico (o {\bf lexing}) y análisis gramático
(o {\bf parsing}) en una pieza de texto.

% parse => parsear
% parsing => parseado

\index{Perl 6 grammar}
Este capítulo está mayormente dedicado este tipo de 
coincidencia, que conduce a la creación de gramáticas completas
que analizan textos estructurados tales como textos XML o HTML, 
documentos JSON o YAML, o hasta programas de computadora: 
los programas de Perl~6 son actualmente analizados sintácticamente
usando una gramática de Perl~6 escrita en Perl~6.

\index{grammar}
Las gramáticas son un tema muy importante en la ciencia de
la computación pero, obviamente, no todos los programadores
escriben gramáticas completas para analizar sintácticamente
lenguajes de programación. No obstante, la escritura de una
gramática simple y un analizador sintáctico simple podría
ser, o quizás debería ser, una actividad mucho más común.

A menudo, la gente invierte demasiado esfuerzo en el descifrado
de archivos simples de configuración con técnicas de bajo nivel,
mientras que la escritura de un simple analizador sintáctico
podría ser mucho más fácil y mucho más eficiente. Perl~6
ofrece todas las herramientas para hacer eso muy fácilmente.
\index{configuration file}

\index{domain-specific language (DSL)}
\index{DSL (domain-specific language)}
\index{sub-language}
\index{slang}

Algunas veces, también necesitas desarrollar un lenguaje 
de dominio específico (DSL por sus siglas en inglés), i.e.,
un sublenguaje relativamente pequeño (también conocido como una
jerga) adaptado a un campo específico del conocimiento
(ciencia, ingeniería, negocios, arte, u otro) con sus propias
convenciones, símbolos, operadores, etc. Con una gramática y la 
habilidad de Perl para crea sus propios operadores, puedes usualmente
expresar conocimiento especializado dentro del marco de terminología
de los expertos de una área del conocimiento en particular.

\section{Programación Declarativa}

\index{declarative programming}
\index{programming!declarative}
Los regexes y las gramáticas son ejemplos de aún otro tipo
de paradigma de programación que no hemos explorado hasta ahora:
{\bf programación declarativa}. Este es un modelo de programación
en el cual, contrario a la programación imperativa o procedimental,
tú no indicas cómo hacer algo ni tampoco eliges tu flujo de control.
En lugar de eso, tú especificas un conjunto de definiciones, reglas,
propiedades, y posiblemente algunas restricciones y acciones, y dejas
al programa aplicar estas definiciones para derivar nueva información
sobre los datos de entrada.

\index{programming!declarative}
\index{programming!logic}
\index{programming!functional}
\index{artificial intelligence}
\index{database query language}
\index{compilation}
\index{Yacc}
\index{Bison}
\index{makefile}

Esta forma de programación se usa extensivamente en la
programación lógica (e.g., Prolog), inteligencia artificial,
sistemas expertos, análisis de datos, lenguajes para
consultar de bases de datos (e.g., SQL), reconocimiento de
texto y código fuente (e.g., Lex y Flex), compilación de
programas (e.g., Yacc o Bison), manejo de configuraciones, 
makefiles, y también de alguna forma, programación funcional.


\section{Capturas}

\index{capturing}
Como explicamos en los ejemplos de regex al comienzo de este 
capítulo, los paréntesis no solo agrupan cosas sino que también
{\bf capturan} datos: ellos hacen que la cadena de texto que 
coincide con el subpatrón dentro de los paréntesis se 
encuentre disponible dentro de una variable especial:
\index{subpattern}

\begin{verbatim}
my $cad =  'número 42';
say "El número es $0" if $cad ~~ /número \s+ (\d+) /;  # -> El número es 42
\end{verbatim}
%

\index{numbered capture}
\index{capture!numbered}
Aquí, el patrón coincidió la cadena de texto \verb|$cad|,
y la parte del patrón dentro de los paréntesis fue capturada
en la variable especial \verb|$0|. Si hay varios grupos 
con paréntesis, ellos serán capturados en las variables
\verb|$0|, \verb|$1|, \verb|$2|, etc. (de izquierda a derecha):

\begin{verbatim}
say "$0 $1 $2" if "abcde" ~~ /(a) b (c) d (e)/;       # -> a c e
\end{verbatim}
%

Esto funciona muy bien con capturas simples, pero el 
número de capturas puede volverse tedioso si hay 
muchas capturas y algo complicado cuando hay paréntesis
anidados en el patrón:

\begin{verbatim}
if 'abc' ~~ / ( a (.) (.) ) / {
    say "Fuera: $0";                   # Fuera: abc
    say "Dentro: $0[0] y $0[1]";       # Dentro: b and c
}
\end{verbatim}

Cuando se vuelve complicado, es usualmente mejor usa
otra características conocida como \emph{capturas nombradas}.
La manera estándar de nombra una captura es de la siguiente forma:
\index{named!capture}
\index{capture!named}

\begin{verbatim}
if 'abc;%' ~~ / $<nombre_de_captura> = \w+ / {
    say ~$<nombre_de_captura>;                # abc
}
\end{verbatim} 

El uso de la captura nombrada, \verb|$<nombre_de_captura>|,
es un atajo para acceder el objeto de coincidencia \verb|$/|
como un hash, en otras palabras: \verb|$/{ 'nombre_de_captura' }|
o \verb|$/<nombre_de_captura>|.
\index{match object}

Las capturas nombradas pueden anidarse usando la sintaxis regular
de captura de grupo:

\begin{verbatim}
if 'abc' ~~ / $<todo>=( a $<parte1>=(.) $<parte2>=(.) ) / {
    say "Todo: $<todo>";                # Todo: abc
    say "Parte 1: $<todo><parte1>";     # Parte 1: b
    say "Parte 2: $<todo><parte2>";     # Parte 2: c
}
\end{verbatim} 

\index{match object}
Asignar el objeto de coincidencia a un hash ofrece acceso programático 
fácil a todas las capturas nombradas:

\begin{verbatim}
if 'abc' ~~ / $<todo>=( a $<parte1>=(.) $<parte2>=(.) ) / {
    my %captura = $/.hash;    
    say ~%captura<todo>;                   # -> abc
    for kv %captura<todo> -> $clave, $val {
        say $clave, " ", ~$val;            # -> parte2 c \n parte1 b
    }
}
\end{verbatim} 

Pero podrías hacer la misma cosa directamente en el objeto de
coincidencia sin tener que hacer una asignación de hash extra:

\begin{verbatim}
if 'abc' ~~ / $<todo>=( a $<parte1>=(.) $<parte2>=(.) ) / {
    say "Todo: $<todo>";                # -> Todo: abc
    for kv %<todo> -> $clave, $val {
        say $clave, " ", ~$val;          # -> parte2 c \n parte1 b
    }
}
\end{verbatim}

Recuerda que, en el código más arriba, \verb|$<todo>| es
realmente un atajo para \verb|$/<todo>|, i.e., para un
tipo de acceso hash al objeto de coincidencia \verb|$/|.

No obstante, existe una manera más conveniente de obtener
capturas nombradas la cual discutimos en la siguiente sección.

\section{Reglas Nombradas (o Subreglas)}
\label{subrules}
\index{subrule}
\index{named!rule}
\index{named!regex}
\index{named!token}

Es posible almacenar piezas de regexes dentro 
de \emph{reglas nombradas}. El ejemplo siguiente usa un
regex nombrado, el cual es un tipo de reglas nombradas, 
para coincidir con una línea de texto:

\begin{verbatim}
my regex línea { \N* \n }  # cualquier número de caracteres excepto
			 # una nueva línea, seguida por 1 nueva línea 

if "abc\ndef" ~~ /<línea> def/ {
    say "Primera línea: ", $<línea>.chomp;      # Primera línea: abc
}
\end{verbatim} 

Nota que la sintaxis con un bloque de código se parece
a la definición de una subrutina o un método. Esto no es una
casualidad; veremos que las reglas nombradas son muy similares
a los métodos. Notablemente, las reglas pueden llamarse unas
a las otras (o hasta algunas veces ellas mismas de forma
recursiva) al igual que los métodos y las subrutinas,
y también veremos que esto es una característica muy poderosa
y expresiva.
\index{recursive rules}

\index{named!regex}
Un regex nombrado puede declararse con 
\verb|my regex nombre { cuerpo del regex }|, y 
llamarse con {\tt <nombre>}.

Como puedes ver en el ejemplo más arriba, un regex
nombrado que es exitoso crea una captura nombrada 
con el mismo nombre. Si necesitas un nombre diferente
para la captura, puedes hacer esto con la siguiente
sintaxis {\tt <nombre-captura=nombre-regex>}. En este
ejemplo, llamamos el mismo regex nombrado dos veces y,
por conveniencia, usamos un nombre diferente para distinguir
las dos capturas:
\index{named!capture}

\begin{verbatim}
my regex línea { \N* \n }
if "abc\ndef\n" ~~ / <primera=línea> <segunda=línea> / {
    say "Primera línea: ", $<primera>.chomp;   # -> Primera línea: abc
    say "Segunda línea: ", $<segunda>.chomp;   # -> Segunda línea: def
    print $_.chomp for $<línea>.list;          # -> abc  def
}
\end{verbatim}

En este ejemplo, usamos las invocaciones del método {\tt chomp}
para remover el carácter de nueva línea de las capturas. Existe
de hecho una manera para coincidir con el carácter de nueva línea
pero excluirla de la captura:

\begin{verbatim}
my regex línea { \N* )> \n }
if "abc\ndef\n" ~~ / <primera=línea> <segunda=línea> / {
    say "Primera línea: ", ~$<primera>;   # -> Primera línea: abc
    say "Segunda línea: ", ~$<segunda>;   # -> Segunda línea: def
    print $<línea>.list;                  # -> abc  def
}
\end{verbatim}

Este poco conocido token, \verb|")>"|, marca el punto final de
la captura completa de una coincidencia. Cualquier cosa después
del token participará en la coincidencia pero no será 
capturado por el regex nombrado. Similarmente, el token 
\verb|")>"| indica el inicio de la captura.

Los regexes nombrados son solo una forma (y probablemente no la
más común) de las reglas nombradas, que vienen en tres sabores
distintos:

\begin{itemize}
\item Regexes nombrados, en la cual el regex se comporta como
los regexes ordinarios
\index{ratchet}
\index{adverb!:ratchet}
\index{backtracking}
\index{token}
\index{named!regex}
\item Tokens nombrados,  en la cual el regex tiene un adverbio
{\tt :ratchet} implícito, lo cual significa que no hay vuelta
atrás
\index{named!token}
\index{ratchet}
\index{adverb!:ratchet}
\index{backtracking}
\index{sigspace}
\index{adverb!:sigspace}
\index{named!rule}
\item Reglas nombradas, en la cual el regex tiene un adverbio
{\tt :ratchet} implícito, como los tokens nombrados, y también
un adverbio {\tt :sigspace} nombrado, lo cual significa que los
espacios en blanco dentro del patrón (o, más específicamente, entre
los caracteres de palabra) no son ignorados
\end{itemize}

En los dos ejemplos arriba, no necesitamos que los regexes
volvieran atrás. Podríamos (y probablemente deberíamos)
haber usado un token nombrado en lugar de un regex nombrado:

\begin{verbatim}
my token línea { \N* \n }
if "abc\ndef" ~~ /<línea> def/ {
    say "Primera línea: ", $<línea>.chomp;    # Primera línea: abc
}
\end{verbatim} 

Pero, para que una regla coincida, tendríamos que remover 
el espacio desde \emph{dentro del patrón}:

\begin{verbatim}
my rule línea { \N*\n }
if "abc\ndef" ~~ /<línea> def/ {
    say "Primera línea: ", $<línea>.chomp;    # Primera línea: abc
}
\end{verbatim} 

Independientemente de la palabra clave específica usada
para sus definiciones, es usual referirse a estos tres tipos
de reglas nombradas colectivamente como {\tt reglas}.
\index{rule}

Recuerdas los varios regexes con los cuales
experimentamos para extraer las fechas de una cadena de
texto en la Subsección~\ref{extracting_dates} 
(p.~\pageref{extracting_dates})? El último ejemplo
usó subpatrones como componentes básicos para 
construir el patrón completo. Podríamos ahora escribirlo,
con la característica añadida para reconocer formatos de
fecha múltiples, en la siguiente manera:
\index{date format}
\index{subpattern}

\index{matching a date}
\begin{verbatim}
my $cadena = "Christmas : 2016-12-25.";                                         
my token año { \d ** 4 }                                        
my token mes {   
    1 <[0..2]>                            # 10 to 12                     
    || 0 <[1..9]>                         # 01 to 09                     
};
my token día { (\d ** 2) <?{1 <= $0 <= 31 }> }  
my token separador { '/' || '-' || '.' } 
my rule fecha {  <año> (<separador>) <mes> $0 <día> 
                || <día> (<separador>) <mes> $0 <año> 
                || <mes>\s<día>',' <año>
}                         

if $cadena ~~ /<fecha>/ {
    say ~$/;                           # -> 2016-12-25
    say "Día\t= " , ~$/<fecha><día>;   # -> 25
    say "Mes\t= " , ~$/<fecha><mes>;   # -> 12
    say "Año\t= " , ~$/<fecha><año>;   # -> 2016
}          
\end{verbatim} 

Los primeros cuatro tokens nombrados definen los componentes
básicos para coincidir con el año, el mes, el día, y los posibles
separados. Después, la regla nombrada {\tt fecha} usa los 
componentes básicos para definir una alternancia entre los 
posibles tres formatos de fecha.
\index{token}
\index{rule}

\index{date!validation}
Este código chequea que el día en el mes esté entre 1 y 31
y que el mes esté entre 01 y 12, y esto es probablemente
suficiente para reconocer fechas en un texto en la 
mayoría de los casos, pero esto coincidiría con ``2016-11-31''
aunque Noviembre tiene solo 30~días. Podemos ser un poco
más estricto sobre las fechas válidas y prevenir eso al
agregar una inserción de código negativa a la regla nombrada
{\tt fecha}:

\index{code assertion}
\index{assertion!code}

\begin{verbatim}
my rule fecha { [ <año> (<separador>) <mes> $0 <día> 
		|| <día> (<separador>) <mes> $0 <año> 
		|| <mes>\s<día>',' <año>
		] <!{ $<día> > 30 and $<mes> == 2|4|6|9|11} >
}
                        
\end{verbatim}

Esto es mejor, pero todavía podemos coincidir con una fecha 
inválida tal como ``2016-02-30''.

\begin{exercise}
\label{february_rule}
%
Como un ejercicio, cambia la aserción de código para
rechazar una fecha como ``Feb. 30``. Si te sientes
valiente, podrías hasta querer chequear el número de días
en febrero dependiendo si la fecha ocurre en un año bisiesto.
También podrías intentar definir y probar otros
formatos de fecha. Solución: \ref{sol_february_rule}
\end{exercise}
\index{leap year}
\index{February!number of days}
\index{date format}

Las reglas pueden (y usualmente deberían) agruparse en 
gramáticas; esa es la razón por la cual fueron diseñadas.

\section{Gramáticas}
\index{grammar}

Las gramáticas son una herramienta poderosa que se utilizan
para analizar datos textuales y usualmente devuelven 
estructuras de datos que se crean al interpretar dichos textos.

Por ejemplo, cualquier programa de Perl~6 se analiza sintácticamente
y se ejecuta usando una gramática de Perl~6 escrita en Perl~6, 
y podrías escribir una gramática para analizar sintácticamente
(casi) cualquier otro lenguaje de programación. Para ser honesto,
los programadores raramente escriben gramáticas analizar sintácticamente
lenguajes de programación. No obstante, las gramáticas son muy útiles para
realizar muchas tareas que son mucho más comunes que analizar
programas sintácticamente.
\index{parsing!HTML}
\index{parsing!XML}
\index{HTML parsing}
\index{XML parsing}

Si alguna vez intentaste usar regexes para analizar una
pieza de texto HTML (o XML)\footnote{No intentes hacerlo.
Ya te lo advertí: no lo hagas.}, probablemente encontraste
que se volvió casi imposible, excepto quizás por las datos
de HTML más fáciles. Para analizar cualquier pieza de tal
datos, necesitas un analizador sintáctico el cual, por su parte,
estará basado en una gramática.

Si no te gustó la gramática en la escuela, no dejes que eso te 
intimide. Las gramáticas de Perl~6 no son complicadas; ellas solo
te permiten agrupar reglas nombradas, en la misma forma que las clases
te permiten agrupar métodos de código regular.

\index{namespace}
\index{parse method}
\index{fileparse method}
\index{grammar!methods}
\index{actions!class}
Una gramática crea un espacio de nombres (del inglés \emph{namespace})
y se introduce con la palabra clave {\tt grammar}. Usualmente
agrupa un número de reglas nombradas, en la misma manera que
una clase agrupa un número de métodos. Una gramática es 
actualmente una clase que hereda de la superclase {\tt Grammar},
la cual provee métodos tales como {\tt parse} para analizar
sintácticamente una cadena de texto y {\tt .parsefile} para
analizar un archivo. Además, puedes actualmente escribir 
algunos métodos en una gramática, e incluso importar algunos
roles. Y, como veremos, las gramáticas son usualmente 
asociadas con algunas {\bf clases de acciones} o 
{\bf objetos de acciones}.

\index{TOP rule}
\index{parsing}
A menos que se diga lo contrario, los métodos de análisis
sintáctico buscarán una regla nombrada por defecto llamada 
``TOP`` (la cual puede ser un regex nombrado, un token, o una 
regla) para comenzar el análisis. Las reglas de análisis 
sintáctico de una fecha que usamos más arriba pueden
ensamblarse en una gramática de la siguiente manera:

\index{grammar!date}
\label{dategrammar}
\begin{verbatim}
grammar Mi-fecha {
    rule TOP { \s*? 
               [    <año> (<separador>) <mes> $0 <día>
                 || <día> (<separador>) <mes> $0 <año> 
                 || <mes>\s<día>',' <año>                     
               ] \s* 
               <!{ ($<día> > 30 and $<mes> ==  2|4|6|9|11)}>  
             }
    token año   { \d ** 4 }                                        
    token mes   {  1 <[0..2]> || 0 <[1..9]> }                
    token día   { (\d ** 2) <?{1 <= $0 <= 31 }> }  
    token separador   { '/' || '-' || '.' } 
}                         

for " 2016/12/25 ", " 2016-02-25 ", " 31/04/2016 " -> $cadena {
	my $coincidencia = Mi-fecha.parse($cadena);
	say ~$coincidencia if defined $coincidencia;
}
\end{verbatim}

Esto imprimirá:
\begin{verbatim}
 2016/12/25
 2016-02-25
\end{verbatim}

\index{code assertion}
La aserción de código dentro de la regla ``TOP`` previene que 
fechas como ``31/04/2016'' coincidan; necesitarías añadir más
código para manejar los finales de las fechas de Febrero, 
como hicimos en la solución del ejercicio anterior (ver
la Subsección~\ref{sol_february_rule}) si esto es importante. 
Podrías querer hacerlo como un ejercicio.

Además de eso, este código no es tan diferente de nuestro
código anterior, pero hay algunos cambios que son significativos.

\index{namespace}
\index{lexical scope}
\index{my!declarator}

Nombré la regla {\tt fecha} como {\tt TOP} porque este
es el nombre por defecto que el método {\tt parse} busca
para la regla en el nivel superior. Una gramática crea su 
propio espacio de nombres y ámbito lexical, y ya no necesito
declarar las reglas con el declarador {\tt my} (el cual se 
requiere para las reglas que se declaran fuera de una 
gramática).
\index{grammar}

Dentro de una gramática, el orden en el cual las reglas
se definen es usualmente irrelevante, así que yo podría 
definir la regla {\tt TOP} primero, aún si usa los tókenes
que se definen después (lo cual no habría sido posible con las
reglas usadas fuera de una gramática). Esto es importante 
porque, dentro de una gramática, puedes tener reglas que se llaman
unas a las otras (o reglas que se llaman a ellas mismas de forma
recursiva), lo cual no sería práctico si el orden de las definiciones
de las reglas fuera importara.
\index{recursive rules}


\index{parse method}
\index{subparse method}
Si analizas la cadena de texto de entrada con el método
{\tt .parse}, la regla {\tt TOP} es automáticamente anclada
al inicio y al final de la cadena de texto, lo que significa que
la gramática tiene que coincidir con la cadena de texto 
completa para ser exitosa. Esta es la razón por la cual
tuvimos que añadir patrones para los espacios en blanco al
inicio y al final de nuestra regla {\tt TOP} para coincidir 
con nuestras cadenas de texto que tienen espacios en blanco
antes y después de la fecha. Existe otro método, \emph{.subspace},
el cual no tiene que alcanzar el final de la cadena de texto
para ser exitoso, pero todavía debemos tener el patrón 
para los espacios en blanco al inicio de la regla.

\section{Herencia de una Gramática}
\index{inheritance!grammar}
\index{grammar!inheritance}
\index{grammar!Message}

Una gramática puede heredar de otra gramática, 
de la misma manera en que una clase puede 
heredar de otra clase.

Considera esta gramática simple (casi simplista) para 
analizar sintácticamente un correo electrónico:

\begin{verbatim}
grammar Mensaje {
    rule  TOP       { <saludo> $<cuerpo>=<línea>+? <final> }
    rule  saludo    { [Saludos||Hola||Hey] $<a>=\S+? ',' }
    rule  final     { Nos vemos luego ',' $<desde>=.+ }
    token línea     { \N* \n}
}
\end{verbatim}

Podemos probarla con el siguiente código:

\begin{verbatim}
my $msg = "Saludos Tomás,
Espero que todo esté bien y que hayas reparado tu carro.
Nos vemos luego, Liz";

my $coincidencia = Mensaje.parse($msg);
if defined $coincidencia { 
    say "Saludo 	 \t= ", ~$coincidencia<saludo>.chomp;
    say "Destinatario\t= $coincidencia<saludo><a>";
    say "Autor   	\t= $coincidencia<final><desde>";
    say "Contenido   \t= $coincidencia<cuerpo>";
}
\end{verbatim}

Esto imprimirá lo siguiente:

\begin{verbatim}
Saludo 	= Saludos Tomás,
Destinatario   = Tomás
Autor          = Liz
Contenido      = Espero que todo esté bien y que hayas reparado tu carro.
\end{verbatim}

Ahora supón que queremos una gramática similar para analizar
un mensaje más formal y notamos que podemos reutilizar parte
de la gramática {\tt Mensaje}. Podemos tener nuestra propia
gramática hija que hereda de la gramática padre:

\index{grammar!Message}
\index{grammar!FormalMessage}
\begin{verbatim}
grammar MensajeFormal is Mensaje {
    rule saludo { [Estimad[a|o]] $<a>=\S+? ',' }
    rule final  { [Sinceramente|Cordiales saludos] ',' $<desde>=.+ }
}
\end{verbatim}

El rasgo {\tt is Mensaje} en la cabecera le dice a Perl que 
{\tt MensajeFormal} debería heredar de la gramática {\tt Mensaje}.
Solo dos reglas, {\tt saludo} y {\tt final}, necesitan ser
definirse nuevamente; las otras (la regla {\tt TOP} y el token
{\tt línea}) serán heredadas desde la gramática {\tt Mensaje}.
\index{grammar inheritance}

Veamos si funciona:

\begin{verbatim}
my $mens_formal = "Estimado Tomás,
dentro se encuentra nuestro factura para junio 2016.
Sinceramente, Elizabeth.";
my $coincid2 = MensajeFormal.parse($mens_formal);
if defined $coincid2 { 
    say "Saludo \t= ", ~$coincid2<saludo>.chomp;
    say "Destinatario\t= $coincid2<saludo><a>";
    say "Autor   \t= $coincid2<final><desde>";
    say "Contenido  \t= $coincid2<cuerpo>";
}
\end{verbatim}

Esto imprimirá:

\begin{verbatim}
Saludo 	= Estimado Tomás,
Destinatario   = Tomás
Autor          = Elizabeth.
Contenido      = dentro se encuentra nuestro factura para junio 2016.
\end{verbatim}

\section{Objetos de Acciones}

\index{actions!object}
\index{actions!class}
\index{action!method}
\index{reduction method}
\index{parse tree}
\index{match object}
\label{actions_object}

Una coincidencia de gramática exitosa te da un árbol de análisis
sintáctico de objetos de coincidencia (objetos del tipo \verb|Match|).
Este árbol recapitula toda las "subcoincidencias" individuales que
contribuyeron a la coincidencia en su totalidad, para que
así pueda volverse muy larga y complicada. Lo más profundo
que el árbol de coincidencia se convierte, y mientras más ramas en 
la gramática, se vuelve más difícil navegar el árbol de 
coincidencia para obtener información que te interesa.

\index{named!rule}
\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
Para evitar la necesidad de adentrarse en un árbol de coincidencia,
puedes proveer un objeto de acciones. Después de cada coincidencia
exitosa de una regla nombrada de tu gramática, el objeto de acciones
intenta invocar un método con un nombre similar a la regla de gramática,
dándole el objeto de coincidencia recién creado como un argumento de posición.
Si tal método no existe, se salta. (Los métodos de una acción son 
algunas veces llamados métodos de reducción). Si existe, 
el método de acción es usualmente usado para construir 
un \emph{árbol de sintaxis abstracta} (AST por sus siglas en inglés),
i.e., una estructura de datos presumiblemente más simple de 
explorar y de usar que un árbol de objeto de coincidencia, 
o puede hacer cualquier otra cosa considerada necesaria.

En este ejemplo algo simplista de una calculadora de operaciones
aritméticas básica, las acciones no tratan de construir un AST 
completo, pero simplemente hacen que el grupo de cálculo funcione
entre los varios tókenes que coinciden con la gramática:
\index{arithmetic calculator}
\index{grammar!arithmetic calculator}

\begin{verbatim}
grammar GramAritmética {
    token TOP { \s* <número> \s* <operación> \s* <número> \s*}
    token operación { <[^*+/-]> }
    token número { \d+ | \d+\.\d+ | \.\d+ }
}

class AccionesAritm {
    method TOP($/) {
        given $<operación> {
            when '*' { $/.make([*] $/<número>)}
            when '+' { $/.make([+] $<número>)}
            when '/' { $/.make($<número>[0] / $<número>[1]) }
            when '-' { $/.make([-] $<número>) }
            when '^' { $/.make($<número>[0] ** $<número>[1]) }
        }
    }
}
for '   6*7  ', '46.2 -4.2', '28+ 14.0 ',
    '70 * .6 ', '126   /3', '6.4807407 ^ 2' -> $op {
        my $coinc = GramAritmética.parse($op, :actions(AccionesAritm));
        say "$coinc\t= ", $coinc.made;
}
\end{verbatim}

Esto imprime lo siguiente:

\begin{verbatim}
   6*7          = 42
46.2 -4.2       = 42
28+ 14.0        = 42
70 * .6         = 42
126   /3        = 42
6.4807407 ^ 2   = 42.00000002063649
\end{verbatim}

El objetivo de este ejemplo no es describir cómo implementar una
calculadora básica (hay maneras mejores de hacer eso, regresaremos
a esto más tarde), pero solo mostrar cómo las acciones pueden usarse
en conjunción con una gramática.
\index{arithmetic calculator}

La gramática es bien simple y busca por dos números decimales separados
por un operador aritmético infijo. Si hay una coincidencia, 
\verb|$/<número>| (o \verb|$<número>| para ser breve) hará referencia
a un array que contiene los dos números (y \verb|$/operación| almacenará
el operador aritmético).

\index{parse method}
\index{actions!object}
\index{actions!class}
El método {\tt parse} se invoca con un argumento nombrado {\tt actions:},
la clase {\tt  AccionesAritm}, que le dice a Perl cual objeto de
acciones debe utilizar con la gramática. En este ejemplo, actualmente no pasamos
un objeto de acciones, pero simplemente el nombre de la clase
de acciones (actualmente un tipo de objeto), porque no hay 
necesidad de instanciar un objeto. En otros casos, por ejemplo si
hubiese una necesidad de inicializar o de algún modo usar
algunos atributos de un objeto, necesitaríamos pasar un 
objeto actual que tendría que ser construido con antelación.

\index{TOP rule}
\index{make method}
\index{AST, abstract syntax tree}
\index{made method}

Siempre que la regla {\tt TOP} es exitosa, el método {\tt TOP}
de la clase {\tt AccionesAritm} es invocado con el objeto de
coincidencia para la regla actual como el argumento. Este método
llama al método {\tt make} sobre el objeto de coincidencia, 
implícitamente puebla el AST, y devuelve el resultado de la
operación aritmética entre los dos números. Después, el método
{\tt make} en el código de la construcción que hace la llamada 
(dentro del bucle {\tt for}) devuelve el resultado que fue asignado
por {\tt make}.

\section{A grammar for Parsing JSON}
\index{JSON grammar}
\index{grammar!JSON}
\index{parsing!JSON}

JSON (\emph{JavaScript Object Notation}) is an 
open-standard format for text data derived from 
the object notation in the JavaScript programming language. 
It has become one of the commonly used standards for 
serializing data structures, which makes it possible, for 
example, to exchange them between different platforms and 
different programming languages, to send them over a network, 
and to store them permanently in files on disks.

\subsection{The JSON Format}
\index{JSON!format}
\index{JSON!object}
\index{JSON!array}

The JSON format is quite simple and is composed of two types 
of structural entities:
\begin{itemize}
\item Objects or unordered lists of name-value pairs 
(basically corresponding to hashes in Perl);
\item Arrays, or ordered lists of values.
\end{itemize}

\index{JSON!base types}
\index{JSON!string}
\index{JSON!Boolean}
\index{JSON!number}
\index{JSON!value}
Values can be either (recursively) objects or arrays 
as defined just above, or basic data types, which are: 
strings, numbers, Boolean (true or false), and \emph{null} 
(empty value or undefined value). A string is a sequence 
of Unicode characters between quotation marks, and numbers 
are signed decimal numbers that may contain a fractional 
part and may use exponential ``E'' notation.

\subsection{Our JSON Sample}
\index{JSON!sample}

To illustrate the format description above and for the 
purpose of our tests, we will use an example borrowed from 
the Wikipedia article on JSON 
(\url{https://en.wikipedia.org/wiki/JSON}), which is a 
possible JSON description of a person:

\begin{verbatim}
{
  "firstName": "John",
  "lastName": "Smith",
  "isAlive": true,
  "age": 25,
  "address": {
    "streetAddress": "21 2nd Street",
    "city": "New York",
    "state": "NY",
    "postalCode": "10021-3100"
  },
  "phoneNumbers": [
    {
      "type": "home",
      "number": "212 555-1234"
    },
    {
      "type": "office",
      "number": "646 555-4567"
    },
    {
      "type": "mobile",
      "number": "123 456-7890"
    }
  ],
  "children": [],
  "spouse": null,  
  "Bank-account": {
    "credit": 2342.25
}
\end{verbatim}

\index{JSON!number}
Compared to the Wikipedia example, we've added a 
\verb'Bank-account' object to provide the possibility 
of testing JSON noninteger numbers.
 
\subsection{Writing the JSON Grammar Step by Step}

Let's take each of the JSON entities in turn and handle 
them with rules.

\subsubsection{Numbers}
\index{JSON!number}

The example JSON document above only has integers and decimal 
numbers, but we need to be able to recognize numbers such 
as ``17,'' ``-138.27,'' ``1.2e-3,'' ``.35,'' etc. We can 
use the following token to do so:

\begin{verbatim}
token number {
    [\+|\-]?              # optional sign
    [ \d+ [ \. \d+ ]? ]   # integer part and optional fractional part
      | [ \. \d+ ]        # or only a fractional part
    [ <[eE]> [\+|\-]? \d+ ]?    # optional exponent
}
\end{verbatim}

\subsubsection{JSON Strings}
\index{JSON!string}
\index{double quote}

There are many possible patterns to define a string. For 
our sample JSON document, the following rule will be 
sufficient:

\begin{verbatim}
token string {
    \" <[ \w \s \- ' ]>+ \" 
}
\end{verbatim}

This will match a double-quoted sequence of alphanumeric 
characters, spaces, dashes, and apostrophes.

For a real JSON parser, a rule using a negative character 
class excluding anything that cannot belong to a string 
might be better, for example:

\begin{verbatim}
token string {
    \" <-[\n " \t]>* \"
}
\end{verbatim}

i.e., a double-quoted sequence of any characters other than 
double quotes, newlines, and tabulations.

You might want to study the JSON standards\footnote{Since 
JSON is actually not completely standardized, I will not provide 
a specific link; look it up and make up your mind.} to figure out 
exactly what is accepted or forbidden in a JSON string. 
For our purposes, the first rule above will be sufficient.

\subsubsection{JSON Objects}
\index{JSON!object}
\index{key-value pair}
\index{JSON!value}
\index{curly bracket}

JSON objects are lists of key-value pairs. Lists are 
delimited by curly braces and pairs separated by 
commas. A key-value pair is a string followed by a colon, 
followed by a value (to be defined later). This can be 
defined as follows:

\begin{verbatim}
rule object     { '{'  <pairlist> '}' }
rule pairlist   { [<pair> [',' <pair>]*] }
rule pair       { <string> ':' <value>  }
\end{verbatim}

\index{modified quantifier}
We can use a regex feature that we haven't seen yet, the 
quantifier modifier, to simplify the {\tt pairlist} 
rule. To more easily match things like comma-separated 
values, you can tack on a \verb'%' modifier to any of 
the regular quantifiers to specify a separator that must 
occur between each of the matches. So, for example 
\verb"/a+ % ','/" will match ``a'' or ``a,a'', or 
``a,a,a'', etc.

Thus, the {\tt pairlist} rule can be rewritten as follows:

\begin{verbatim}
rule pairlist   {<pair> + % \,}
\end{verbatim}

or:

\begin{verbatim}
rule pairlist   {<pair> * % \,}
\end{verbatim}

if we accept that a {\tt pairlist} may also be empty.

\subsubsection{JSON Arrays}
\index{JSON!array}

Arrays are comma-separated lists of values between square 
brackets:

\begin{verbatim}
rule array       { '[' <valueList> ']'}
rule valueList {  <value> * % \, }
\end{verbatim}

Here, we again used the modified quantifier shown 
just above.

\subsubsection{JSON Values}
\index{JSON!value}

Values are objects, arrays, string, numbers, Booleans 
(true or false), or \emph{null}:

\begin{verbatim}
token value { | <object> | <array> | <string> | <number> 
              | true     | false   | null 
}
\end{verbatim}

\subsection{The JSON Grammar}
\index{JSON!grammar}

We have defined all the elements of the JSON grammar; we 
only need to declare a grammar and to add a {\tt TOP} rule 
to complete it:

\begin{verbatim}
grammar JSON-Grammar {
    token TOP      { \s* [ <object> | <array> ] \s* }
    rule object    { '{' \s* <pairlist> '}' \s* }
    rule pairlist  {  <pair> * % \, }
    rule pair      {  <string>':' <value> }
    rule array     { '[' <valueList> ']'}
    rule valueList {  <value> * % \, }
    token string   {  \" <[ \w \s \- ' ]>+ \"  }
    token number   { 
      [\+|\-]?  
      [ \d+ [ \. \d+ ]? ] | [ \. \d+ ]  
      [ <[eE]> [\+|\-]? \d+ ]?
    }
    token value    { <object> | <array> | <string> | <number> 
                     | true   | false   | null 
    }
}
\end{verbatim}

We can now test the grammar with our sample JSON string 
and try to print the match object:

\begin{verbatim}
my $match = JSON-Grammar.parse($JSON-string);
say ~$match if $match;
\end{verbatim}
\index{parse}

This produces the following output:

\begin{verbatim}
{
  "firstName": "John",
  "lastName": "Smith",
  "isAlive": true,
  "age": 25,
  "address": {
    "streetAddress": "21 2nd Street
    "city": "New York",
    "state": "NY",
    "postalCode": "10021-3100"
  },
  "phoneNumbers": [
    {
      "type": "home",
      "number": "212 555-1234"
    },
    {
      "type": "office",
      "number": "646 555-4567"
    },
    {
      "type": "mobile",
      "number": "123 456-7890"
    }
  ],
  "children": [],
  "spouse": null,
  "Bank-account": {
        "credit": 2342.25
  }
}
\end{verbatim}

The sample JSON document has been fully matched. This 
JSON grammar works perfectly on it, and takes less than 
20~lines of code. If you think about it, this is 
really powerful. Test it for yourself. Try to change 
the grammar in various places to see if it still works. 
You could also try to introduce errors into the JSON 
document (for example to remove a comma between two values 
of a list) and the match should no longer occur (or, at least, 
should not be the same).

You may object that this grammar covers only a subset 
of JSON. This is sort of true, but not really: it is almost complete. 
True, I would not recommend using this grammar 
in a production environment for parsing JSON documents, 
because it has been built only for pedagogical purposes 
and may not comply with every single fine detail of the JSON 
standards.

Take a look at the grammar of the Perl~6 {\tt JSON::Tiny} 
module (\url{https://github.com/moritz/json}), which can 
parse any valid JSON document. It is not much more 
complicated than what we have shown here (except for the use 
of proto regexes, a topic that we haven't covered here), and 
it is not much longer, as it contains about 35~code lines.

\subsection{Adding Actions}
\index{actions!object}
\index{actions!class}
\index{parse tree}

The JSON grammar works fine, but printing out the tree of 
parse objects just for our relatively small JSON document 
will display about 300 lines of text, as 
it provides all the details of everything that has been 
matched, rule by rule and subpattern by subpattern. This 
can be very useful in helping you to understand what the grammar does 
(especially when it does not work as expected), but 
exploring that tree to extract the data can be quite 
tedious. You can use \emph{actions} to populate a simpler 
tree structure (often called an abtract syntax tree) containing 
only the information you really need. 
\index{subpattern}

\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
Let us add an actions class to build an abstract syntax tree 
(AST):

\begin{verbatim}
class JSON-actions {
    method TOP($/) {
        make $/.values.[0].made;
    };
    method object($/) {
        make $<pairlist>.made.hash.item;
    }
    method pairlist($/) {
        make $<pair>».made.flat;
    }
    method pair($/) {
        make $<string>.made => $<value>.made;
    }
    method array($/) {
        make $<valueList>.made.item;
    }
    method valueList($/) {
        make [$<value>.map(*.made)];
    }
    method string($/) { make ~$0 }
    method number($/) { make +$/.Str; }
    method value($/) { 
        given ~$/ {
            when "true"  {make Bool::True;}
            when "false" {make Bool::False;}
            when "null"  {make Any;}
            default { make $<val>.made;}
        }  
   }
}
\end{verbatim}

\index{named!capture}
For this actions class to work, we need to make a small change 
to the grammar. The {\tt value} method uses a {\tt val} named 
capture to access its content; we need to add the relevant 
named captures to the {\tt value} token:

\begin{verbatim}
token value { <val=object> | <val=array> | <val=string> 
              | <val=number> | true | false | null
}
\end{verbatim}

We can now call our grammar with the following syntax:

\begin{verbatim}
my $j-actions = JSON-actions.new();
my $match = JSON-Grammar.parse($JSON-string, :actions($j-actions));
say $match.made;
\end{verbatim}

Notice that, here, we've used an actions object rather than 
simply the actions class, but this is just for the purpose of 
showing how to do it; we could have used the class directly 
as before.
\index{actions!object}
\index{actions!class}

\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
The last statement in the above code prints out the AST. 
We have reformatted the output to better show the 
structure of the AST:

\begin{verbatim}
{
    Bank-account => {
        credit => 2342.25
    }, 
    address => {
        city => New York, 
        postalCode => 10021-3100, 
        state => NY, 
        streetAddress => 21 2nd Street
    }, 
    age => 25, 
    children => [], 
    firstName => John, 
    isAlive => True, 
    lastName => Smith, 
    phoneNumbers => [
        {number => 212 555-1234, type => home} 
        {number => 646 555-4567, type => office} 
        {number => 123 456-7890, type => mobile}
    ], 
    spouse => (Any)
}
\end{verbatim}

In this case, the top structure is a hash (it could also have been 
an array with a different JSON input string). We can now explore 
this hash to find the data of interest to us. For example:
\index{AST, abstract syntax tree}

\begin{verbatim}
say "Keys are: \n", $match.made.keys;
say "\nSome values:";
say $match.made{$_} for <firstName lastName isAlive>;
say $match.made<address><city>;
say "\nPhone numbers:";
say $match.made<phoneNumbers>[$_]<type number> 
    for 0..$match.made<phoneNumbers>.end;
\end{verbatim}

This will display the following output:

\begin{verbatim}
Keys are:
(lastName Bank-account phoneNumbers children address age firstName spouse isAlive)

Some values:
John
Smith
True
New York

Phone numbers:
(home 212 555-1234)
(office 646 555-4567)
(mobile 123 456-7890)
\end{verbatim}

\section{Herencia y Gramáticas Mutables}

\index{grammar!subclassing}
\index{grammar!mutable}
\index{grammar!inheritance}
La capacidad de una gramática de heredar de otra abre la
puerta para muchas posibilidades en términos de la extensión
del lenguaje Perl~6. Es posible, por ejemplo en el contexto de
un módulo o una framework, crear una ``subclase`` de la 
gramática estándar de Perl~6, i.e., para escribir una nueva
gramática hija que hereda de la gramática estándar de Perl~6, pero
agrega una nueva característica, sobrecarga un operador, o modifica
algún otro elemento sintáctico, y ejecuta este programa con el 
mismo compilador de Perl~6, pero con una gramática modificada
localmente.

Esto significa que es actualmente posible extender el lenguaje 
dinámicamente para necesidades nuevas, usualmente sin cambiar
el compilador o la máquina virtual. No obstante, estos son temas
avanzados que están dedicados más a los gurús del lenguaje 
que a los principiantes. Así que solo mencionamos estas posibilidades
grandiosas con la esperanza de estimular tu apetito y empujarte a
que los estudies en más detalles, pero no hablaremos en más detalle
sobre ellos en este libro.
\index{extending the language}

\section{Depuración de Programas}

La escritura de gramáticas es muy divertido, pero también difícil
o hasta tedioso cuando comienzas.
\index{fun}

Cuando comenzaste a practicar la programación con este libro,
probablemente cometiste muchos pequeños errores que inicialmente
previnieron que tus programas se compilaran y se ejecutaran, o
hicieran lo que querías. Con la práctica, sin embargo, con suerte
cometiste menos errores gradualmente y gastaste menos tiempo 
persiguiendo errores.


Cuando comienzas a aprender sobre gramáticas (y en menor medida regexes),
puedes sentirte que estás nuevamente en el punto de partida. Inclusive
programadores muy buenos usualmente cometen errores absurdos cuando
comienzan a escribir gramáticas. Es un diferente paradigma de programación,
y requiere una nueva fase de aprendizaje.
\index{grammar!debugging}

\index{testing}
En este caso, pequeño es hermoso. Inicia con regexes pequeños y reglas pequeñas,
y con una pequeña entrada de prueba. Prueba los regexes o las reglas individuales
en el REPL, y agrégalos a tu código solo cuando estás confiado
de que hacen lo que deseas.

Escribe casos de prueba al mismo tiempo que escribe tu código 
(o actualmente hasta antes de escribir tu código), y asegúrate de
que pasen todos las pruebas relevantes antes de seguir adelante.
Y agrega nuevas pruebas al agregar reglas nuevas.


Una técnica de depuración estándar es agregar sentencias de 
impresión al código para inquirir información sobre el estado
del programa (tal como el valor de variables, el flujo de
ejecución del programa, etc.). También puedes hacer eso con
los regexes y las gramáticas.

Tomemos el ejemplo de la gramática simple para coincidir
con las fechas de la Sección~\ref{dategrammar} y supongamos
que escribiste esta gramática:

\begin{verbatim}
grammar Mi-Fecha {
    token TOP { \s* <año> '-' <mes> '-' <día> }
    token año  { \d ** 4 }                                        
    token mes  {  1 <[0..2]> || 0 <[1..9]> }                
    token día  { (\d ** 2) <?{1 <= $0 <= 31 }> }  
}                         
my $cadena = " 2016-07-31 ";
say so Mi-Fecha.parse($cadena);                 # -> False
\end{verbatim}

Esta prueba falla.

A esta altura, ya se ha vuelto un poco difícil de inquirir
por qué la gramática falla (a menos que hayamos probado cada
uno de los tres tókenes antes de construir la gramática,
pero en aras de esta discusión asumamos que no lo hemos hecho).
Intentemos no cambiar aleatoriamente cosas aquí o allá y observar
si funciona; podríamos investir horas haciendo eso y probablemente
no llegaríamos a ninguna parte. Seamos más metódicos.

Primero probemos los tókenes básicos, {\tt año}, {\tt mes}, y {\tt día}.
Hemos visto anteriormente que el método {\tt parse} busca por defecto
la regla {\tt TOP} en la gramática, pero puedes especificar otra 
regla si así deseas, y eso es lo que necesitamos aquí. 
Podemos probar estos tókenes individualmente:

\begin{verbatim}
say so Mi-Fecha.parse("2016", :rule<año>);    # -> True
say so Mi-Fecha.parse("07",   :rule<mes>);    # -> True
say so Mi-Fecha.parse("31",   :rule<día>);    # -> True
\end{verbatim}

Estos tres tókenes parecen funcionar apropiadamente. En este punto,
podrías adivinar dónde se encuentra el problema, pero 
asumamos que no sabes.

Necesitamos depurar el token ``TOP``. Podemos usar el método común
de depuración de imprimir donde estamos a varias etapas del
programa. Puedes insertar una sentencia de impresión en
una regla nombrada. Intentemos cambiar el token TOP a esto:

\begin{verbatim}
    token TOP { \s* <año> { say "año coincidido"; }
                '-' <mes> { say "mes coincidido";}
                '-' <día> { say "día coincidido";  }
              }
\end{verbatim}

Esto muestra la siguiente salida:

\begin{verbatim}
año coincidido
mes coincidido
día coincidido
\end{verbatim}


Incluso el token ``TOP`` parecen funcionar hasta el final. 
En este punto, deberíamos ser capaz de deducir que nos falta
el espacio final en el token ``TOP``.

Así que podríamos agregar un espacio adicional al final del
token:

\begin{verbatim}
token TOP { \s* <año> '-' <mes> '-' <día> \s*}
\end{verbatim}

o cambiar la regla:

\begin{verbatim}
rule TOP { \s* <año> '-' <mes> '-' <día> }
\end{verbatim}

o era posible probar la cadena de texto que era incorrecta (porque
no podría tener espacios) y por lo tanto, necesitaba ser arreglada.

Si tiene una clase de acciones, también puedes agregar sentencias de
impresión a los métodos de acciones.
\index{actions!class}

\index{debugger}
\index{debugger!stepping through a regex}
Igualmente recuerda que el depurador de Perl~6 (ver 
la Sección~\ref{perl-debugger}) puede ser muy útil. 
Brevemente mostramos en la Subsección~\ref{regex-debugging} 
(p.~\pageref{regex-debugging}) cómo recorrer una coincidencia
de regex paso a paso. La mayor parte de lo que se describió 
ahí también aplica a la depuración de gramáticas.

\index{debugger!debugging grammars}
Finalmente, vale la pena mencionar que existe un buen módulo, \verb|Grammar::Tracer|, 
para la depuración de regexes y gramáticas (\url{https://github.com/jnthn/grammar-debugger/}), 
que funciona con Rakudo. Si agregas:

\begin{verbatim}
use Grammar::Tracer;
\end{verbatim}
\index{Grammar::Tracer}

a tu programa, entonces cualquier gramática dentro del ámbito lexical
imprimirá información de depuración sobre las reglas con la cual
intentó coincidir, aquellas que fueron exitosas y aquellas que 
fallaron.

Puedes también usar lo siguiente:

\begin{verbatim}
use Grammar::Debugger;
\end{verbatim}
\index{Grammar::Debugger}

para hacer lo mismo paso a paso. Solo escribe ``h`` en la 
prompt para la lista de comandos disponibles.


\section{Glosario}

\begin{description}

\index{grammar}
\item[Gramática] Una herramienta de alto nivel para realizar
análisis léxico y gramático de un texto estructurado. En Perl~6, 
una gramática es específicamente un espacio de nombres que 
contiene una colección de reglas nombradas destinada a este 
tipo de análisis.

\index{lexing}
\item[Análisis semántico] El proceso en el cual se realiza
un análisis léxico de texto fuente, y especialmente dividirlo
en ``palabras`` o tókenes.

\index{parsing}
\item[Análisis sintáctico] El proceso en el cual se realiza un
análisis gramático de un texto fuente, y especialmente se ensamblan
palabras o tókenes en expresiones y sentencias que 
tienen sentido semántico.

\index{declarative programming}
\index{programming!declarative}
\item[Programación declarativa] Un modelo de programación donde
especificas definiciones, reglas, propiedades, y restricciones, 
en lugar de sentencias e instrucciones, y dejas al programa derivar
conocimiento nuevo de estas definiciones y reglas.  Los regexes
y las gramáticas son ejemplos de la programación declarativa.

\index{match object}
\item[Objeto de coincidencia] En Perl~6, un objeto (de tipo {\tt Match}),
denotado usualmente por \verb|$/|, el cual contiene información 
(algunas veces muy) detalla sobre lo que coincidió exitosamente
con un regex o una gramática. El objeto de coincidencia \verb|$/|
se le asignará {\tt Nil} si la coincidencia falla.

\index{capture}
\item[Captura] El hecho por el cual partes de una cadena de texto
que coinciden con un regex (o una gramática) pueden extraerse
a través del uso de un número de variables especiales.

\index{rule}
\item[Regla] En términos generales, las reglas nombradas son regexes
que usan una sintaxis de método y usualmente se almacenan en una
gramática. Más específicamente, una categoría de estas reglas nombradas
(en conjunto con los regexes nombrados y los tókenes).

\index{AST, abstract syntax tree}
\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
\item[Árbol de sintaxis abstracta(AST):] Una estructura de datos
que usualmente resume el objeto de coincidencia y se usa para la
explotación de datos útiles. El objeto de coincidencia es poblado 
automáticamente por Perl, donde ek AST contiene información considerada
útil y explícitamente insertada por el programador.

\index{actions!class}
\item[Clases de acciones] Una clase usada en conjunción con una gramática
para realizar ciertas acciones cuando una regla de una gramática coincide
con algo en los datos de entrada. Si un método con el mismo nombre
de una regla en la gramática existe en la clase de acciones,
entonces será invocado siempre que la regla coincide.

\end{description}

\section{Ejercicio: Una Gramática para una Calculadora Aritmética}
\label{calculator}
\index{calculator}
\index{calculator!grammar}
\index{grammar!arithmetic calculator}
\index{arithmetic calculator}

La calculadora aritmética presentada en la Sección~\ref{actions_object}
más arriba es muy simple. En particular, puede analizar sintácticamente
expresiones aritméticas compuestas de dos operandos separados
por un operador infijo, pero no mucho más.

Nos gustaría ser capaz de analizar expresiones aritméticas complicadas.
La calculadora debería también ser capaz de manejar:
\begin{itemize}
\item Expresiones con varios operadores diferentes (entre los
cuatro operadores aritméticos básicos) y operandos múltiples
\item Reglas estándares de precedencia entre los operadores (por ejemplo,
las multiplicaciones deben hacerse antes que las adiciones)
\index{precedence}
\item Paréntesis anulan las reglas usuales de precedencia
\index{parentheses}
\index{parentheses!overriding precedence rule}
\end{itemize}

Estos son algunos ejemplos de expresiones que la calculadora
debería analizar sintácticamente y calcular correctamente:
\index{parse}
\begin{verbatim}
3 + 4 + 5;
3 + 4 * 5;   # resultado debería ser 23
(3 + 4) * 5; # resultado debería ser 35 
\end{verbatim}

\begin{exercise}
Tu misión, \verb'[Juan|Salomé]', así elijas aceptarla, es escribir
tal gramática. Como es usual, si fallas, el Gobierno debería negar
cualquier conocimiento de tu clase de acciones.
\index{actions!class}

Hay varias maneras posibles de lograr esto; la solución 
presentada en la Sección~\ref{sol_calculator} es solo una de ellas.
\end{exercise}

