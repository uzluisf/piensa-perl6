


\chapter{Regexes y Gramáticas}
\label{regex_grammars}
\index{regex}
\index{regular expression}
\index{grammar}

Las expresiones regulares o regexes fueron introducidas en las
Secciones~\ref{regex} a \ref{substitutions}. Es recomendable que leas
esas secciones nuevamente antes de leer este capítulo si no 
recuerdas mucho sobre los regexes. No necesitas recordar los detalles
de todo lo que discutimos anteriormente y explicaremos de nuevo, aunque
brevemente, las partes específicas de la funcionalidad que usaremos,
pero se espera que entiendas cómo los regexes funcionan en general.

\section{Una Breve Actualización}

\index{pattern}
Los regexes, como los estudiamos hasta ahora, tratan sobre
la exploración de cadenas de texto usando patrones. 
Un patrón es una secuencia de caracteres (usualmente especiales)
que describen una cadena de texto o parte de una 
cadena de texto. Un patrón coincide con una cadena de texto si existe
una correspondencia entre el patrón y la cadena de texto.

Por ejemplo, el siguiente fragmento de código inspecciona la 
cadena de texto y trata de encontrar la letra ``a``, seguida por 
cualquier número (pero por lo menos una) de letras ``b`` o ``c``,
seguida por cero o más dígitos seguidos por una ``B`` o una ``C``:

\begin{verbatim}
my $cad = "foo13abbccbcbcbb42Cbar";
say ~$/ if $cad ~~ /a <[bc]>+ (\d*) [B|C]/;  # -> abbccbcbcbb42C
say ~$0;                                     # -> 42
\end{verbatim}

\index{smart match operator}
\index{operator!smart match}
Este fragmento de código usa el operador de coincidencia 
inteligente \verb|~~| para chequear si la cadena \verb|$cad|
coincide con el patrón \verb'/a <[bc]>+ (\d*) [B|C]/'. Recuerda
que los espacios en blanco no son usualmente significativos en 
un patrón de regex (a menos que se especifiquen).
\index{pattern}

El patrón está compuesto por los siguientes componentes:

\begin{itemize}

\item \verb'a': una coincidencia literal de la letra ``a''

\index{character class}
\item \verb'<[bc]>+': el átomo \verb'<[bc]>' es una categoría de caracteres
que se refiere a la letra ``b`` o ``c``; el cuantificador \verb|+|
dicta que los caracteres que coinciden con la categoría de caracteres
``b`` o ``c`` pueden repetirse una o más veces.

\index{quantifier}
\index{capture!regex}
\item \verb'(\d*)': el átomo \verb|\d| es una categoría de caracteres
que son dígitos, el cuantificador \verb|*| significa 0 o más ocurrencias
del átomo anterior, y los paréntesis requieren una captura
de estos dígitos (si existen) en la variable \verb|$0| (una variable especial
que es realmente un atajo para \verb|$/[0]|)


\index{alternation}
\item \verb'[B|C]': \verb'B|C' es una alternación (una ``B`` o un ``C``),
y los corchetes reagrupan esta alternación en un (y también habilita 
precedencia adecuada).
\index{subpattern}

\end{itemize}

\index{match object}
Si la coincidencia es exitosa (como en este ejemplo), 
el resultado se almacena en el \emph{objeto de coincidencia},
\verb|$/|. La impresión de \verb|~$/| muestra una versión en
cadena de texto del objeto de coincidencia. Y la impresión de \verb|$0|
(o \verb|$/[0]|) muestra la captura (la porción de la coincidencia
entre los paréntesis, en este caso el número ``42``).
\index{capture}
\index{regex!capture}
\index{match object}

\index{lexing}
\index{parsing}
\index{lexical analysis}
\index{grammatical analysis}
Esto es lo que se llama coincidencia a un bajo nivel:
el reconocimiento del patrón se hace mayormente al nivel
individual de un carácter. Perl~6 ofrece varias maneras de 
agrupar y nombrar los patrones de regex para que estos
patrones individuales puedan utilizarse posteriormente 
como componentes básicos para coincidencia a un alto nivel:
el reconocimiento de palabras y secuencias de palabras (más
que caracteres), para el propósito de hacer lo que se conoce
como análisis léxico (o {\bf lexing}) y análisis gramático
(o {\bf parsing}) en una pieza de texto.

% parse => parsear
% parsing => parseado

\index{Perl 6 grammar}
Este capítulo está mayormente dedicado este tipo de 
coincidencia, que conduce a la creación de gramáticas completas
que analizan textos estructurados tales como textos XML o HTML, 
documentos JSON o YAML, o hasta programas de computadora: 
los programas de Perl~6 son actualmente analizados sintácticamente
usando una gramática de Perl~6 escrita en Perl~6.

\index{grammar}
Las gramáticas son un tema muy importante en la ciencia de
la computación pero, obviamente, no todos los programadores
escriben gramáticas completas para analizar sintácticamente
lenguajes de programación. No obstante, la escritura de una
gramática simple y un analizador sintáctico simple podría
ser, o quizás debería ser, una actividad mucho más común.

A menudo, la gente invierte demasiado esfuerzo en el descifrado
de archivos simples de configuración con técnicas de bajo nivel,
mientras que la escritura de un simple analizador sintáctico
podría ser mucho más fácil y mucho más eficiente. Perl~6
ofrece todas las herramientas para hacer eso muy fácilmente.
\index{configuration file}

\index{domain-specific language (DSL)}
\index{DSL (domain-specific language)}
\index{sub-language}
\index{slang}

Algunas veces, también necesitas desarrollar un lenguaje 
de dominio específico (DSL por sus siglas en inglés), i.e.,
un sublenguaje relativamente pequeño (también conocido como una
jerga) adaptado a un campo específico del conocimiento
(ciencia, ingeniería, negocios, arte, u otro) con sus propias
convenciones, símbolos, operadores, etc. Con una gramática y la 
habilidad de Perl para crea sus propios operadores, puedes usualmente
expresar conocimiento especializado dentro del marco de terminología
de los expertos de una área del conocimiento en particular.

\section{Programación Declarativa}

\index{declarative programming}
\index{programming!declarative}
Los regexes y las gramáticas son ejemplos de aún otro tipo
de paradigma de programación que no hemos explorado hasta ahora:
{\bf programación declarativa}. Este es un modelo de programación
en el cual, contrario a la programación imperativa o procedimental,
tú no indicas cómo hacer algo ni tampoco eliges tu flujo de control.
En lugar de eso, tú especificas un conjunto de definiciones, reglas,
propiedades, y posiblemente algunas restricciones y acciones, y dejas
al programa aplicar estas definiciones para derivar nueva información
sobre los datos de entrada.

\index{programming!declarative}
\index{programming!logic}
\index{programming!functional}
\index{artificial intelligence}
\index{database query language}
\index{compilation}
\index{Yacc}
\index{Bison}
\index{makefile}

Esta forma de programación se usa extensivamente en la
programación lógica (e.g., Prolog), inteligencia artificial,
sistemas expertos, análisis de datos, lenguajes para
consultar de bases de datos (e.g., SQL), reconocimiento de
texto y código fuente (e.g., Lex y Flex), compilación de
programas (e.g., Yacc o Bison), manejo de configuraciones, 
makefiles, y también de alguna forma, programación funcional.


\section{Capturas}

\index{capturing}
Como explicamos en los ejemplos de regex al comienzo de este 
capítulo, los paréntesis no solo agrupan cosas sino que también
{\bf capturan} datos: ellos hacen que la cadena de texto que 
coincide con el subpatrón dentro de los paréntesis se 
encuentre disponible dentro de una variable especial:
\index{subpattern}

\begin{verbatim}
my $cad =  'número 42';
say "El número es $0" if $cad ~~ /número \s+ (\d+) /;  # -> El número es 42
\end{verbatim}
%

\index{numbered capture}
\index{capture!numbered}
Aquí, el patrón coincidió la cadena de texto \verb|$cad|,
y la parte del patrón dentro de los paréntesis fue capturada
en la variable especial \verb|$0|. Si hay varios grupos 
con paréntesis, ellos serán capturados en las variables
\verb|$0|, \verb|$1|, \verb|$2|, etc. (de izquierda a derecha):

\begin{verbatim}
say "$0 $1 $2" if "abcde" ~~ /(a) b (c) d (e)/;       # -> a c e
\end{verbatim}
%

Esto funciona muy bien con capturas simples, pero el 
número de capturas puede volverse tedioso si hay 
muchas capturas y algo complicado cuando hay paréntesis
anidados en el patrón:

\begin{verbatim}
if 'abc' ~~ / ( a (.) (.) ) / {
    say "Fuera: $0";                   # Fuera: abc
    say "Dentro: $0[0] y $0[1]";       # Dentro: b and c
}
\end{verbatim}

Cuando se vuelve complicado, es usualmente mejor usa
otra características conocida como \emph{capturas nombradas}.
La manera estándar de nombra una captura es de la siguiente forma:
\index{named!capture}
\index{capture!named}

\begin{verbatim}
if 'abc;%' ~~ / $<nombre_de_captura> = \w+ / {
    say ~$<nombre_de_captura>;                # abc
}
\end{verbatim} 

El uso de la captura nombrada, \verb|$<nombre_de_captura>|,
es un atajo para acceder el objeto de coincidencia \verb|$/|
como un hash, en otras palabras: \verb|$/{ 'nombre_de_captura' }|
o \verb|$/<nombre_de_captura>|.
\index{match object}

Las capturas nombradas pueden anidarse usando la sintaxis regular
de captura de grupo:

\begin{verbatim}
if 'abc' ~~ / $<todo>=( a $<parte1>=(.) $<parte2>=(.) ) / {
    say "Todo: $<todo>";                # Todo: abc
    say "Parte 1: $<todo><parte1>";     # Parte 1: b
    say "Parte 2: $<todo><parte2>";     # Parte 2: c
}
\end{verbatim} 

\index{match object}
Asignar el objeto de coincidencia a un hash ofrece acceso programático 
fácil a todas las capturas nombradas:

\begin{verbatim}
if 'abc' ~~ / $<todo>=( a $<parte1>=(.) $<parte2>=(.) ) / {
    my %captura = $/.hash;    
    say ~%captura<todo>;                   # -> abc
    for kv %captura<todo> -> $clave, $val {
        say $clave, " ", ~$val;            # -> parte2 c \n parte1 b
    }
}
\end{verbatim} 

Pero podrías hacer la misma cosa directamente en el objeto de
coincidencia sin tener que hacer una asignación de hash extra:

\begin{verbatim}
if 'abc' ~~ / $<todo>=( a $<parte1>=(.) $<parte2>=(.) ) / {
    say "Todo: $<todo>";                # -> Todo: abc
    for kv %<todo> -> $clave, $val {
        say $clave, " ", ~$val;          # -> parte2 c \n parte1 b
    }
}
\end{verbatim}

Recuerda que, en el código más arriba, \verb|$<todo>| es
realmente un atajo para \verb|$/<todo>|, i.e., para un
tipo de acceso hash al objeto de coincidencia \verb|$/|.

No obstante, existe una manera más conveniente de obtener
capturas nombradas la cual discutimos en la siguiente sección.

\section{Reglas Nombradas (o Subreglas)}
\label{subrules}
\index{subrule}
\index{named!rule}
\index{named!regex}
\index{named!token}

Es posible almacenar piezas de regexes dentro 
de \emph{reglas nombradas}. El ejemplo siguiente usa un
regex nombrado, el cual es un tipo de reglas nombradas, 
para coincidir con una línea de texto:

\begin{verbatim}
my regex línea { \N* \n }  # cualquier número de caracteres excepto
			 # una nueva línea, seguida por 1 nueva línea 

if "abc\ndef" ~~ /<línea> def/ {
    say "Primera línea: ", $<línea>.chomp;      # Primera línea: abc
}
\end{verbatim} 

Nota que la sintaxis con un bloque de código se parece
a la definición de una subrutina o un método. Esto no es una
casualidad; veremos que las reglas nombradas son muy similares
a los métodos. Notablemente, las reglas pueden llamarse unas
a las otras (o hasta algunas veces ellas mismas de forma
recursiva) al igual que los métodos y las subrutinas,
y también veremos que esto es una característica muy poderosa
y expresiva.
\index{recursive rules}

\index{named!regex}
Un regex nombrado puede declararse con 
\verb|my regex nombre { cuerpo del regex }|, y 
llamarse con {\tt <nombre>}.

Como puedes ver en el ejemplo más arriba, un regex
nombrado que es exitoso crea una captura nombrada 
con el mismo nombre. Si necesitas un nombre diferente
para la captura, puedes hacer esto con la siguiente
sintaxis {\tt <nombre-captura=nombre-regex>}. En este
ejemplo, llamamos el mismo regex nombrado dos veces y,
por conveniencia, usamos un nombre diferente para distinguir
las dos capturas:
\index{named!capture}

\begin{verbatim}
my regex línea { \N* \n }
if "abc\ndef\n" ~~ / <primera=línea> <segunda=línea> / {
    say "Primera línea: ", $<primera>.chomp;   # -> Primera línea: abc
    say "Segunda línea: ", $<segunda>.chomp;   # -> Segunda línea: def
    print $_.chomp for $<línea>.list;          # -> abc  def
}
\end{verbatim}

En este ejemplo, usamos las invocaciones del método {\tt chomp}
para remover el carácter de nueva línea de las capturas. Existe
de hecho una manera para coincidir con el carácter de nueva línea
pero excluirla de la captura:

\begin{verbatim}
my regex línea { \N* )> \n }
if "abc\ndef\n" ~~ / <primera=línea> <segunda=línea> / {
    say "Primera línea: ", ~$<primera>;   # -> Primera línea: abc
    say "Segunda línea: ", ~$<segunda>;   # -> Segunda línea: def
    print $<línea>.list;                  # -> abc  def
}
\end{verbatim}

Este poco conocido token, \verb|")>"|, marca el punto final de
la captura completa de una coincidencia. Cualquier cosa después
del token participará en la coincidencia pero no será 
capturado por el regex nombrado. Similarmente, el token 
\verb|")>"| indica el inicio de la captura.

Los regexes nombrados son solo una forma (y probablemente no la
más común) de las reglas nombradas, que vienen en tres sabores
distintos:

\begin{itemize}
\item Regexes nombrados, en la cual el regex se comporta como
los regexes ordinarios
\index{ratchet}
\index{adverb!:ratchet}
\index{backtracking}
\index{token}
\index{named!regex}
\item Tokens nombrados,  en la cual el regex tiene un adverbio
{\tt :ratchet} implícito, lo cual significa que no hay vuelta
atrás
\index{named!token}
\index{ratchet}
\index{adverb!:ratchet}
\index{backtracking}
\index{sigspace}
\index{adverb!:sigspace}
\index{named!rule}
\item Reglas nombradas, en la cual el regex tiene un adverbio
{\tt :ratchet} implícito, como los tokens nombrados, y también
un adverbio {\tt :sigspace} nombrado, lo cual significa que los
espacios en blanco dentro del patrón (o, más específicamente, entre
los caracteres de palabra) no son ignorados
\end{itemize}

En los dos ejemplos arriba, no necesitamos que los regexes
volvieran atrás. Podríamos (y probablemente deberíamos)
haber usado un token nombrado en lugar de un regex nombrado:

\begin{verbatim}
my token línea { \N* \n }
if "abc\ndef" ~~ /<línea> def/ {
    say "Primera línea: ", $<línea>.chomp;    # Primera línea: abc
}
\end{verbatim} 

Pero, para que una regla coincida, tendríamos que remover 
el espacio desde \emph{dentro del patrón}:

\begin{verbatim}
my rule línea { \N*\n }
if "abc\ndef" ~~ /<línea> def/ {
    say "Primera línea: ", $<línea>.chomp;    # Primera línea: abc
}
\end{verbatim} 

Independientemente de la palabra clave específica usada
para sus definiciones, es usual referirse a estos tres tipos
de reglas nombradas colectivamente como {\tt reglas}.
\index{rule}

Recuerdas los varios regexes con los cuales
experimentamos para extraer las fechas de una cadena de
texto en la Subsección~\ref{extracting_dates} 
(p.~\pageref{extracting_dates})? El último ejemplo
usó subpatrones como componentes básicos para 
construir el patrón completo. Podríamos ahora escribirlo,
con la característica añadida para reconocer formatos de
fecha múltiples, en la siguiente manera:
\index{date format}
\index{subpattern}

\index{matching a date}
\begin{verbatim}
my $cadena = "Christmas : 2016-12-25.";                                         
my token año { \d ** 4 }                                        
my token mes {   
    1 <[0..2]>                            # 10 to 12                     
    || 0 <[1..9]>                         # 01 to 09                     
};
my token día { (\d ** 2) <?{1 <= $0 <= 31 }> }  
my token separador { '/' || '-' || '.' } 
my rule fecha {  <año> (<separador>) <mes> $0 <día> 
                || <día> (<separador>) <mes> $0 <año> 
                || <mes>\s<día>',' <año>
}                         

if $cadena ~~ /<fecha>/ {
    say ~$/;                           # -> 2016-12-25
    say "Día\t= " , ~$/<fecha><día>;   # -> 25
    say "Mes\t= " , ~$/<fecha><mes>;   # -> 12
    say "Año\t= " , ~$/<fecha><año>;   # -> 2016
}          
\end{verbatim} 

Los primeros cuatro tokens nombrados definen los componentes
básicos para coincidir con el año, el mes, el día, y los posibles
separados. Después, la regla nombrada {\tt fecha} usa los 
componentes básicos para definir una alternancia entre los 
posibles tres formatos de fecha.
\index{token}
\index{rule}

\index{date!validation}
Este código chequea que el día en el mes esté entre 1 y 31
y que el mes esté entre 01 y 12, y esto es probablemente
suficiente para reconocer fechas en un texto en la 
mayoría de los casos, pero esto coincidiría con ``2016-11-31''
aunque Noviembre tiene solo 30~días. Podemos ser un poco
más estricto sobre las fechas válidas y prevenir eso al
agregar una inserción de código negativa a la regla nombrada
{\tt fecha}:

\index{code assertion}
\index{assertion!code}

\begin{verbatim}
my rule fecha { [ <año> (<separador>) <mes> $0 <día> 
		|| <día> (<separador>) <mes> $0 <año> 
		|| <mes>\s<día>',' <año>
		] <!{ $<día> > 30 and $<mes> == 2|4|6|9|11} >
}
                        
\end{verbatim}

Esto es mejor, pero todavía podemos coincidir con una fecha 
inválida tal como ``2016-02-30''.

\begin{exercise}
\label{february_rule}
%
Como un ejercicio, cambia la aserción de código para
rechazar una fecha como ``Feb. 30``. Si te sientes
valiente, podrías hasta querer chequear el número de días
en febrero dependiendo si la fecha ocurre en un año bisiesto.
También podrías intentar definir y probar otros
formatos de fecha. Solución: \ref{sol_february_rule}
\end{exercise}
\index{leap year}
\index{February!number of days}
\index{date format}

Las reglas pueden (y usualmente deberían) agruparse en 
gramáticas; esa es la razón por la cual fueron diseñadas.

\section{Grammars}
\index{grammar}

Grammars are a powerful tool used to analyze textual data 
and often to return data structures that have been 
created by interpreting that text.

For example, any Perl~6 program is parsed and executed 
using a Perl~6 grammar written in Perl~6, and you could write a grammar 
for parsing (almost) any other programming language. 
To tell the truth, programmers rarely 
write grammars for parsing programming languages. But 
grammars are very useful for performing many tasks 
that are much more common than parsing programs.

\index{parsing!HTML}
\index{parsing!XML}
\index{HTML parsing}
\index{XML parsing}

If you ever tried to use regexes for analyzing a piece 
of HTML (or XML) text\footnote{Don't try to do it. Now, 
I warned you: just don't do it.}, you 
probably found out that this is quickly becoming next 
to impossible, except perhaps for the most simple 
HTML data. For analyzing any piece of such data, you 
need an actual parser which, in turn, will usually be 
based on an underlying grammar.

If you didn't like grammar in school, don't let that 
scare you off grammars. Perl~6 grammars are nothing complicated; 
they just allow you to group named rules, just as classes 
allow you to group methods of regular code.

\index{namespace}
\index{parse method}
\index{fileparse method}
\index{grammar!methods}
\index{actions!class}
A grammar creates a namespace and is introduced with the 
keyword {\tt grammar}. It usually groups a number of 
named rules, in the same way a class groups 
a number of methods. A grammar is actually a class that 
inherits from the {\tt Grammar} superclass, which provides 
methods such as {\tt parse} to analyze a string and 
{\tt .parsefile} to analyze a file. Moreover, you can 
actually write some methods in a grammar, and even import 
some roles. And, as we shall see, grammars are often 
associated with some {\bf actions classes} or 
{\bf actions objects}.

\index{TOP rule}
\index{parsing}
Unless told otherwise, the parsing methods will look for 
a default rule named ``TOP'' (which may be a named regex, 
token, or rule) to start the parsing. The date parsing rules 
used above might be assembled into a grammar as follows:

\index{grammar!date}
\label{dategrammar}
\begin{verbatim}
grammar My-date {
    rule TOP { \s*? 
               [    <year> (<sep>) <month> $0 <day>
                 || <day> (<sep>) <month> $0 <year> 
                 || <month>\s<day>',' <year>                     
               ] \s* 
               <!{ ($<day> > 30 and $<month> ==  2|4|6|9|11)}>  
             }
    token year  { \d ** 4 }                                        
    token month {  1 <[0..2]> || 0 <[1..9]> }                
    token day   { (\d ** 2) <?{1 <= $0 <= 31 }> }  
    token sep   { '/' || '-' } 
}                         

for " 2016/12/25 ", " 2016-02-25 ", " 31/04/2016 " -> $string {
	my $matched = My-date.parse($string);
	say ~$matched if defined $matched;
}
\end{verbatim}

This will print out:
\begin{verbatim}
 2016/12/25
 2016-02-25
\end{verbatim}

\index{code assertion}
The code assertion within the ``TOP'' rule prevents invalid 
dates such as ``31/04/2016'' from being matched; you would 
need to add some code for handling the end of February dates,
as we did in the solution to the previous exercise (see 
Subsection~\ref{sol_february_rule}) if this is important. You may 
want to do it as an exercise.

Besides that, this code is not very different from our 
earlier code, but there are a few changes that are 
significant.

\index{namespace}
\index{lexical scope}
\index{my!declarator}

I renamed the {\tt date} rule as {\tt TOP} because this 
is the default name searched by {\tt parse} for the top-level 
rule. A grammar creates its own namespace and 
lexical scope, and I no longer need to declare the rules 
with the {\tt my} declarator (which is required for
rules declared outside of a grammar). 
\index{grammar}

Within a grammar, the order in which the rules are 
defined is generally not relevant, so that I could define 
the {\tt TOP} rule first, even though it uses tokens 
that are defined afterwards (which again would have not 
been possible with rules used outside a grammar). This is 
important because, within a grammar, you can have many rules 
that call each other (or rules that call themselves 
recursively), which would be impractical if the order of 
the rule definitions mattered.
\index{recursive rules}


\index{parse method}
\index{subparse method}
If you're parsing the input string with the {\tt .parse} method,
the {\tt TOP} rule is automatically anchored to the start and end 
of the string, which means that the grammar has to match 
the whole string to be successful. This is why we had to 
add patterns for spaces at the beginning and at the end of 
our {\tt TOP} rule to match our strings which have some 
spaces before and after the date itself. There is another 
method, \emph'.subparse', which does not have to reach the 
end of the string to be successful, but we would still need to 
have the space pattern at the beginning of the rule.

\section{Grammar Inheritance}
\index{inheritance!grammar}
\index{grammar!inheritance}
\index{grammar!Message}

A grammar can inherit from another grammar, just as a 
class can inherit from another class.

Consider this very simple (almost simplistic) grammar 
for parsing a mail message:

\begin{verbatim}
grammar Message {
    rule  TOP    { <greet> $<body>=<line>+? <end> }
    rule greet    { [Hi||Hello||Hey] $<to>=\S+? ',' }
    rule end      { Later dude ',' $<from>=.+ }
    token line    { \N* \n}
}
\end{verbatim}

We can test it with the following code:

\begin{verbatim}
my $msg = "Hello Tom,
I hope you're well and that your car is now repaired.
Later dude, Liz";

my $matched = Message.parse($msg);
if defined $matched { 
    say "Greeting \t= ", ~$matched<greet>.chomp;
    say "Addressee\t= $matched<greet><to>";
    say "Author   \t= $matched<end><from>";
    say "Content  \t= $matched<body>";
}
\end{verbatim}

This will print out the following:

\begin{verbatim}
Greeting        = Hello Tom,
Addressee       = Tom
Author          = Liz
Content         = I hope you're well and that your car is now repaired.
\end{verbatim}

Suppose now that we want a similar grammar for parsing 
a more formal message and we figure out that we could 
reuse part of the {\tt Message} grammar. We can have our 
new child grammar inherit from the existing parent:

\index{grammar!Message}
\index{grammar!FormalMessage}
\begin{verbatim}
grammar FormalMessage is Message {
    rule greet { [Dear] $<to>=\S+? ',' }
    rule end { [Yours sincerely|Best regards] ',' $<from>=.+ }
}
\end{verbatim}

The {\tt is Message} trait in the header tells Perl that 
{\tt FormalMessage} should inherit from the {\tt Message} grammar. 
Only two rules, {\tt greet} and {\tt end}, need to be 
redefined; the others (the {\tt TOP} rule 
and the {\tt line} token) will be inherited from the 
{\tt Message} grammar.
\index{grammar inheritance}

Let's try some code to run it:

\begin{verbatim}
my $formal_msg = "Dear Thomas,
enclosed is our invoice for June 2016.
Best regards, Elizabeth.";
my $matched2 = FormalMessage.parse($formal_msg);
if defined $matched2 { 
    say "Greeting \t= ", ~$matched2<greet>.chomp;
    say "Addressee\t= $matched2<greet><to>";
    say "Author   \t= $matched2<end><from>";
    say "Content  \t= $matched2<body>";
}
\end{verbatim}

This will print:

\begin{verbatim}
Greeting        = Dear Thomas,
Addressee       = Thomas
Author          = Elizabeth.
Content         = enclosed is our invoice for June 2016.
\end{verbatim}

\section{Actions Objects}

\index{actions!object}
\index{actions!class}
\index{action!method}
\index{reduction method}
\index{parse tree}
\index{match object}
\label{actions_object}

A successful grammar match gives you a parse tree of 
match objects (objects of \verb'Match' type). This tree 
recapitulates all the individual 
``submatches'' that contributed to the overall match, so 
it can quickly become very large and complicated. 
The deeper that match tree gets, and the more branches in 
the grammar there are, the harder it becomes to navigate the 
match tree to get the information you are actually 
interested in.

\index{named!rule}
\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
To avoid the need for diving deep into a match tree, you 
can supply an actions object. After each successful match 
of a named rule in your grammar, it tries to call a method 
with the same name as the grammar rule, giving it the 
newly created match object as a positional argument. 
If no such method exists, it is skipped. (Action methods 
are sometimes also called reduction methods.) If it exists, 
the action method is often used to construct an \emph{abstract 
syntax tree (AST)}, i.e., a data structure presumably 
simpler to explore and to use than the match object tree, 
or it can do any other thing deemed to be useful.

In this somewhat simplistic example of a basic arithmetic  
calculator, the actions don't try to build a complete AST, but simply 
do the bulk of the calculation work between the various tokens
matched by the grammar:
\index{arithmetic calculator}
\index{grammar!arithmetic calculator}

\begin{verbatim}
grammar ArithmGrammar {
    token TOP { \s* <num> \s* <operation> \s* <num> \s*}
    token operation { <[^*+/-]> }
    token num { \d+ | \d+\.\d+ | \.\d+ }
}
class ArithmActions {
    method TOP($/) {
        given $<operation> {
            when '*' { $/.make([*] $/<num>)}
            when '+' { $/.make([+] $<num>)}
            when '/' { $/.make($<num>[0] / $<num>[1]) }
            when '-' { $/.make([-] $<num>) }
            when '^' { $/.make($<num>[0] ** $<num>[1]) }
        }
    }
}
for '   6*7  ', '46.2 -4.2', '28+ 14.0 ',
    '70 * .6 ', '126   /3', '6.4807407 ^ 2' -> $op {
        my $match = ArithmGrammar.parse($op, :actions(ArithmActions));
        say "$match\t= ", $match.made;
}
\end{verbatim}

This prints the following output:

\begin{verbatim}
   6*7          = 42
46.2 -4.2       = 42
28+ 14.0        = 42
70 * .6         = 42
126   /3        = 42
6.4807407 ^ 2   = 42.00000002063649
\end{verbatim}

The aim of this example is not to describe how to implement 
a basic calculator (there are better ways to do that, we'll 
come back to that), but only to show how actions may be 
used in conjunction with a grammar.
\index{arithmetic calculator}

The grammar is quite simple and is looking for two decimal numbers 
separated by an infix arithmetic operator. If there is a 
match, \verb|$/<num>| (or \verb|$<num>| for short) will refer to an 
array containing the two numbers (and \verb|$/<operation>| 
will contain the arithmetic operator).

\index{parse method}
\index{actions!object}
\index{actions!class}
The {\tt parse} 
method is called with an {\tt actions:} named argument, 
the {\tt ArithmActions} class, which tells Perl which 
actions object to use with the grammar. In this example, we 
don't really pass an action object, but simply the name 
of the actions class (actually a type object), 
because there is no need to instantiate an object. In 
other cases, for example if there was a need to initialize 
or somehow use some object attributes, we would need to pass 
an actual object that would have to be constructed beforehand.

\index{TOP rule}
\index{make method}
\index{AST, abstract syntax tree}
\index{made method}
Whenever the {\tt TOP} rule succeeds, the {\tt TOP} method 
of class {\tt ArithmActions} is invoked with the match 
object for the current rule as the argument.  This method 
calls the {\tt make} method on the match object, implicitly 
populates the AST, and returns the result of the actual 
arithmetic operation between the two numbers. Then, the 
{\tt made} method in the caller code (within the 
{\tt for} loop) returns that result that was set by {\tt make}.

\section{A grammar for Parsing JSON}
\index{JSON grammar}
\index{grammar!JSON}
\index{parsing!JSON}

JSON (\emph{JavaScript Object Notation}) is an 
open-standard format for text data derived from 
the object notation in the JavaScript programming language. 
It has become one of the commonly used standards for 
serializing data structures, which makes it possible, for 
example, to exchange them between different platforms and 
different programming languages, to send them over a network, 
and to store them permanently in files on disks.

\subsection{The JSON Format}
\index{JSON!format}
\index{JSON!object}
\index{JSON!array}

The JSON format is quite simple and is composed of two types 
of structural entities:
\begin{itemize}
\item Objects or unordered lists of name-value pairs 
(basically corresponding to hashes in Perl);
\item Arrays, or ordered lists of values.
\end{itemize}

\index{JSON!base types}
\index{JSON!string}
\index{JSON!Boolean}
\index{JSON!number}
\index{JSON!value}
Values can be either (recursively) objects or arrays 
as defined just above, or basic data types, which are: 
strings, numbers, Boolean (true or false), and \emph{null} 
(empty value or undefined value). A string is a sequence 
of Unicode characters between quotation marks, and numbers 
are signed decimal numbers that may contain a fractional 
part and may use exponential ``E'' notation.

\subsection{Our JSON Sample}
\index{JSON!sample}

To illustrate the format description above and for the 
purpose of our tests, we will use an example borrowed from 
the Wikipedia article on JSON 
(\url{https://en.wikipedia.org/wiki/JSON}), which is a 
possible JSON description of a person:

\begin{verbatim}
{
  "firstName": "John",
  "lastName": "Smith",
  "isAlive": true,
  "age": 25,
  "address": {
    "streetAddress": "21 2nd Street",
    "city": "New York",
    "state": "NY",
    "postalCode": "10021-3100"
  },
  "phoneNumbers": [
    {
      "type": "home",
      "number": "212 555-1234"
    },
    {
      "type": "office",
      "number": "646 555-4567"
    },
    {
      "type": "mobile",
      "number": "123 456-7890"
    }
  ],
  "children": [],
  "spouse": null,  
  "Bank-account": {
    "credit": 2342.25
}
\end{verbatim}

\index{JSON!number}
Compared to the Wikipedia example, we've added a 
\verb'Bank-account' object to provide the possibility 
of testing JSON noninteger numbers.
 
\subsection{Writing the JSON Grammar Step by Step}

Let's take each of the JSON entities in turn and handle 
them with rules.

\subsubsection{Numbers}
\index{JSON!number}

The example JSON document above only has integers and decimal 
numbers, but we need to be able to recognize numbers such 
as ``17,'' ``-138.27,'' ``1.2e-3,'' ``.35,'' etc. We can 
use the following token to do so:

\begin{verbatim}
token number {
    [\+|\-]?              # optional sign
    [ \d+ [ \. \d+ ]? ]   # integer part and optional fractional part
      | [ \. \d+ ]        # or only a fractional part
    [ <[eE]> [\+|\-]? \d+ ]?    # optional exponent
}
\end{verbatim}

\subsubsection{JSON Strings}
\index{JSON!string}
\index{double quote}

There are many possible patterns to define a string. For 
our sample JSON document, the following rule will be 
sufficient:

\begin{verbatim}
token string {
    \" <[ \w \s \- ' ]>+ \" 
}
\end{verbatim}

This will match a double-quoted sequence of alphanumeric 
characters, spaces, dashes, and apostrophes.

For a real JSON parser, a rule using a negative character 
class excluding anything that cannot belong to a string 
might be better, for example:

\begin{verbatim}
token string {
    \" <-[\n " \t]>* \"
}
\end{verbatim}

i.e., a double-quoted sequence of any characters other than 
double quotes, newlines, and tabulations.

You might want to study the JSON standards\footnote{Since 
JSON is actually not completely standardized, I will not provide 
a specific link; look it up and make up your mind.} to figure out 
exactly what is accepted or forbidden in a JSON string. 
For our purposes, the first rule above will be sufficient.

\subsubsection{JSON Objects}
\index{JSON!object}
\index{key-value pair}
\index{JSON!value}
\index{curly bracket}

JSON objects are lists of key-value pairs. Lists are 
delimited by curly braces and pairs separated by 
commas. A key-value pair is a string followed by a colon, 
followed by a value (to be defined later). This can be 
defined as follows:

\begin{verbatim}
rule object     { '{'  <pairlist> '}' }
rule pairlist   { [<pair> [',' <pair>]*] }
rule pair       { <string> ':' <value>  }
\end{verbatim}

\index{modified quantifier}
We can use a regex feature that we haven't seen yet, the 
quantifier modifier, to simplify the {\tt pairlist} 
rule. To more easily match things like comma-separated 
values, you can tack on a \verb'%' modifier to any of 
the regular quantifiers to specify a separator that must 
occur between each of the matches. So, for example 
\verb"/a+ % ','/" will match ``a'' or ``a,a'', or 
``a,a,a'', etc.

Thus, the {\tt pairlist} rule can be rewritten as follows:

\begin{verbatim}
rule pairlist   {<pair> + % \,}
\end{verbatim}

or:

\begin{verbatim}
rule pairlist   {<pair> * % \,}
\end{verbatim}

if we accept that a {\tt pairlist} may also be empty.

\subsubsection{JSON Arrays}
\index{JSON!array}

Arrays are comma-separated lists of values between square 
brackets:

\begin{verbatim}
rule array       { '[' <valueList> ']'}
rule valueList {  <value> * % \, }
\end{verbatim}

Here, we again used the modified quantifier shown 
just above.

\subsubsection{JSON Values}
\index{JSON!value}

Values are objects, arrays, string, numbers, Booleans 
(true or false), or \emph{null}:

\begin{verbatim}
token value { | <object> | <array> | <string> | <number> 
              | true     | false   | null 
}
\end{verbatim}

\subsection{The JSON Grammar}
\index{JSON!grammar}

We have defined all the elements of the JSON grammar; we 
only need to declare a grammar and to add a {\tt TOP} rule 
to complete it:

\begin{verbatim}
grammar JSON-Grammar {
    token TOP      { \s* [ <object> | <array> ] \s* }
    rule object    { '{' \s* <pairlist> '}' \s* }
    rule pairlist  {  <pair> * % \, }
    rule pair      {  <string>':' <value> }
    rule array     { '[' <valueList> ']'}
    rule valueList {  <value> * % \, }
    token string   {  \" <[ \w \s \- ' ]>+ \"  }
    token number   { 
      [\+|\-]?  
      [ \d+ [ \. \d+ ]? ] | [ \. \d+ ]  
      [ <[eE]> [\+|\-]? \d+ ]?
    }
    token value    { <object> | <array> | <string> | <number> 
                     | true   | false   | null 
    }
}
\end{verbatim}

We can now test the grammar with our sample JSON string 
and try to print the match object:

\begin{verbatim}
my $match = JSON-Grammar.parse($JSON-string);
say ~$match if $match;
\end{verbatim}
\index{parse}

This produces the following output:

\begin{verbatim}
{
  "firstName": "John",
  "lastName": "Smith",
  "isAlive": true,
  "age": 25,
  "address": {
    "streetAddress": "21 2nd Street
    "city": "New York",
    "state": "NY",
    "postalCode": "10021-3100"
  },
  "phoneNumbers": [
    {
      "type": "home",
      "number": "212 555-1234"
    },
    {
      "type": "office",
      "number": "646 555-4567"
    },
    {
      "type": "mobile",
      "number": "123 456-7890"
    }
  ],
  "children": [],
  "spouse": null,
  "Bank-account": {
        "credit": 2342.25
  }
}
\end{verbatim}

The sample JSON document has been fully matched. This 
JSON grammar works perfectly on it, and takes less than 
20~lines of code. If you think about it, this is 
really powerful. Test it for yourself. Try to change 
the grammar in various places to see if it still works. 
You could also try to introduce errors into the JSON 
document (for example to remove a comma between two values 
of a list) and the match should no longer occur (or, at least, 
should not be the same).

You may object that this grammar covers only a subset 
of JSON. This is sort of true, but not really: it is almost complete. 
True, I would not recommend using this grammar 
in a production environment for parsing JSON documents, 
because it has been built only for pedagogical purposes 
and may not comply with every single fine detail of the JSON 
standards.

Take a look at the grammar of the Perl~6 {\tt JSON::Tiny} 
module (\url{https://github.com/moritz/json}), which can 
parse any valid JSON document. It is not much more 
complicated than what we have shown here (except for the use 
of proto regexes, a topic that we haven't covered here), and 
it is not much longer, as it contains about 35~code lines.

\subsection{Adding Actions}
\index{actions!object}
\index{actions!class}
\index{parse tree}

The JSON grammar works fine, but printing out the tree of 
parse objects just for our relatively small JSON document 
will display about 300 lines of text, as 
it provides all the details of everything that has been 
matched, rule by rule and subpattern by subpattern. This 
can be very useful in helping you to understand what the grammar does 
(especially when it does not work as expected), but 
exploring that tree to extract the data can be quite 
tedious. You can use \emph{actions} to populate a simpler 
tree structure (often called an abtract syntax tree) containing 
only the information you really need. 
\index{subpattern}

\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
Let us add an actions class to build an abstract syntax tree 
(AST):

\begin{verbatim}
class JSON-actions {
    method TOP($/) {
        make $/.values.[0].made;
    };
    method object($/) {
        make $<pairlist>.made.hash.item;
    }
    method pairlist($/) {
        make $<pair>».made.flat;
    }
    method pair($/) {
        make $<string>.made => $<value>.made;
    }
    method array($/) {
        make $<valueList>.made.item;
    }
    method valueList($/) {
        make [$<value>.map(*.made)];
    }
    method string($/) { make ~$0 }
    method number($/) { make +$/.Str; }
    method value($/) { 
        given ~$/ {
            when "true"  {make Bool::True;}
            when "false" {make Bool::False;}
            when "null"  {make Any;}
            default { make $<val>.made;}
        }  
   }
}
\end{verbatim}

\index{named!capture}
For this actions class to work, we need to make a small change 
to the grammar. The {\tt value} method uses a {\tt val} named 
capture to access its content; we need to add the relevant 
named captures to the {\tt value} token:

\begin{verbatim}
token value { <val=object> | <val=array> | <val=string> 
              | <val=number> | true | false | null
}
\end{verbatim}

We can now call our grammar with the following syntax:

\begin{verbatim}
my $j-actions = JSON-actions.new();
my $match = JSON-Grammar.parse($JSON-string, :actions($j-actions));
say $match.made;
\end{verbatim}

Notice that, here, we've used an actions object rather than 
simply the actions class, but this is just for the purpose of 
showing how to do it; we could have used the class directly 
as before.
\index{actions!object}
\index{actions!class}

\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
The last statement in the above code prints out the AST. 
We have reformatted the output to better show the 
structure of the AST:

\begin{verbatim}
{
    Bank-account => {
        credit => 2342.25
    }, 
    address => {
        city => New York, 
        postalCode => 10021-3100, 
        state => NY, 
        streetAddress => 21 2nd Street
    }, 
    age => 25, 
    children => [], 
    firstName => John, 
    isAlive => True, 
    lastName => Smith, 
    phoneNumbers => [
        {number => 212 555-1234, type => home} 
        {number => 646 555-4567, type => office} 
        {number => 123 456-7890, type => mobile}
    ], 
    spouse => (Any)
}
\end{verbatim}

In this case, the top structure is a hash (it could also have been 
an array with a different JSON input string). We can now explore 
this hash to find the data of interest to us. For example:
\index{AST, abstract syntax tree}

\begin{verbatim}
say "Keys are: \n", $match.made.keys;
say "\nSome values:";
say $match.made{$_} for <firstName lastName isAlive>;
say $match.made<address><city>;
say "\nPhone numbers:";
say $match.made<phoneNumbers>[$_]<type number> 
    for 0..$match.made<phoneNumbers>.end;
\end{verbatim}

This will display the following output:

\begin{verbatim}
Keys are:
(lastName Bank-account phoneNumbers children address age firstName spouse isAlive)

Some values:
John
Smith
True
New York

Phone numbers:
(home 212 555-1234)
(office 646 555-4567)
(mobile 123 456-7890)
\end{verbatim}

\section{Inheritance and Mutable Grammars}

\index{grammar!subclassing}
\index{grammar!mutable}
\index{grammar!inheritance}
The capacity for a grammar to inherit from another one opens 
the door to very rich possibilities in terms of 
extending the Perl~6 language itself. It is possible, for 
example in the context of a module or a framework, to ``subclass'' 
the standard Perl grammar, i.e., to write a new child grammar that 
inherits from the standard Perl grammar, but adds a new 
feature, overloads an operator, or modifies some other syntax 
element, and to run this program with the same Perl~6 compiler,
but with this locally modified grammar.

This means that it is actually possible to dynamically extend 
the language for new needs, often without even changing the compiler 
or the virtual machine. These are however advanced topics that 
are more geared towards language gurus than to beginners. So 
we only mention these exciting possibilities with the hope of 
whetting your appetite and pushing you to study these further, 
but will not dwell further on them in this book.
\index{extending the language}

\section{Debugging}

Writing grammars is a lot of fun, but it can also be difficult 
or even tedious when you start.
\index{fun}

When you started to practice programming with this book, you probably 
made a lot of small mistakes that initially prevented your 
programs from compiling and running, or from doing what 
you expected. With practice, however, you hopefully gradually 
made fewer errors and spent less time chasing bugs.

When you begin to learn grammars (and to a lesser extent regexes), 
you may feel like you are starting again at square one. Even 
very good programmers often make silly mistakes when they start 
writing grammars. It is a different programming paradigm, and 
it requires a new learning phase.
\index{grammar!debugging}

\index{testing}
In this case, small is beautiful. Start with small regexes and 
small rules, and with small test input. Test individual regexes 
or rules under the REPL, and add them to your code only when 
you're confident that they do what you want.

Write test cases at the same time as your code (or actually even 
before you write the code), and make sure that you pass all the 
relevant tests before moving on. And add new tests when you add 
new rules.

One standard debugging technique is to add print statements 
to the code in order to figure out various information about 
the state of the program (such as the value of variables, the 
flow of execution of the program, etc.). You can also do that 
with regexes and grammars.

Let's take the example of the very simple grammar for 
matching dates of Section~\ref{dategrammar} and let's suppose 
that you have written this grammar:

\begin{verbatim}
grammar My-Date {
    token TOP { \s* <year> '-' <month> '-' <day> }
    token year  { \d ** 4 }                                        
    token month {  1 <[0..2]> || 0 <[1..9]> }                
    token day   { (\d ** 2) <?{1 <= $0 <= 31 }> }  
}                         
my $string = " 2016-07-31 ";
say so My-Date.parse($string);                 # -> False
\end{verbatim}

This test fails.

At this point, it has already become a bit difficult to figure 
out why the grammar fails (unless we have thoroughly tested 
each of the three tokens before building the grammar, but 
let's assume for the sake of this discussion that we haven't).
Let's try not to randomly change things here or there and see 
if it works better; we would be likely to spend hours doing 
that and probably not get anywhere. Let's be more methodical.

Let's first test the building-block tokens, {\tt year}, 
{\tt month}, and {\tt day}. We've seen before that 
the {\tt parse} method looks \emph{by default} for the {\tt TOP} 
rule in the grammar, but you can specify another rule, and 
that's what we need here. We can test these tokens individually:

\begin{verbatim}
say so My-Date.parse("2016", :rule<year>);    # -> True
say so My-Date.parse("07",   :rule<month>);   # -> True
say so My-Date.parse("31",   :rule<day>);     # -> True
\end{verbatim}

These three tokens seem to work fine. At this point, you 
might be guessing where the problem is, but let's assume 
you don't.

We need to debug the ``TOP'' token. We can just use the common 
debugging method of printing where we are at various stages 
of the program. You can insert a print statement block 
in a named rule. Let's try to change the TOP token to this:

\begin{verbatim}
    token TOP { \s* <year>  { say "matched year"; }
                '-' <month> { say "matched month";}
                '-' <day>   { say "matched day";  }
              }
\end{verbatim}
 
This displays the following output:

\begin{verbatim}
matched year
matched month
matched day
\end{verbatim}

So, even the ``TOP'' token seems to work almost to the end. At 
this point, we should be able to figure out that we lack 
final spacing in the ``TOP'' token. 

So either we should add an optional spacing at the end of 
the token:

\begin{verbatim}
token TOP { \s* <year> '-' <month> '-' <day> \s*}
\end{verbatim}

or change it to a rule:

\begin{verbatim}
rule TOP { \s* <year> '-' <month> '-' <day> }
\end{verbatim}

or it was possibly the test string that was wrong (because 
it wasn't supposed to have spaces) and needed to be fixed.

If you have an actions class, you can also add print statements 
to the actions methods.
\index{actions!class}

\index{debugger}
\index{debugger!stepping through a regex}
Remember also that the Perl debugger (see 
Section~\ref{perl-debugger}) can be very helpful. We 
briefly showed in Subsection~\ref{regex-debugging} 
(p.~\pageref{regex-debugging}) how to go step by step 
through a regex match. Most of what has been described 
there also applies to debugging grammars.

\index{debugger!debugging grammars}
Finally, there is a very good module, \verb'Grammar::Tracer', for 
debugging regexes and grammars (\url{https://github.com/jnthn/grammar-debugger/}), that works with Rakudo. If you add:

\begin{verbatim}
use Grammar::Tracer;
\end{verbatim}
\index{Grammar::Tracer}

to your program, then any grammar within the lexical scope will 
print out debugging information about the rules which tried to 
match, those which succeeded and those which failed.

You can also use the following:

\begin{verbatim}
use Grammar::Debugger;
\end{verbatim}
\index{Grammar::Debugger}

to do the same thing step by step. Just type ``h'' at the 
prompt for a list of available commands.


\section{Glossary}

\begin{description}

\index{grammar}
\item[Grammar] A high level tool for performing lexical and 
grammatical analysis of structured text. In Perl~6, 
a grammar is more specifically a namespace containing a 
collection of named rules aimed at this type of analysis.

\index{lexing}
\item[Lexing] Performing a lexical analysis of a source text, and especially dividing it into ``words'' or tokens.

\index{parsing}
\item[Parsing] Performing a grammatical analysis of a source text, 
and especially assembling words or tokens into sentences or 
expressions and statements that make some semantic sense. 

\index{declarative programming}
\index{programming!declarative}
\item[Declarative programming] a programming model where you 
specify definitions, rules, properties, and constraints, rather 
than statements and instructions, and let the program derive 
new knowledge from these definitions and rules. Regexes and 
grammars are examples of declarative programming.

\index{match object}
\item[Match object] in Perl~6, an object (of type {\tt Match}), 
usually noted \verb'$/', which contains (sometimes very) 
detailed information about what was successfully matched 
by a regex or a grammar. The \verb'$/' match object will be 
set to {\tt Nil} if the match failed.

\index{capture}
\item[Capture] the fact that parts of the target string that 
are matched by a regex (or a grammar) can be retrieved through 
the use of a number of dedicated special variables.

\index{rule}
\item[Rule] in broad terms, named rules are regexes that use a 
method syntax and are usually stored in a grammar. More specifically, 
one category of these named rules (along with named regexes and 
tokens).

\index{AST, abstract syntax tree}
\index{abstract syntax tree (AST)}
\index{AST, abstract syntax tree}
\item[Abstract syntax tree (AST):] a data structure often 
summarizing the match object and used for further exploitation 
of the useful data. The match object is populated automatically 
by Perl, whereas the AST contains information deemed useful and 
explicitly inserted by the programmer.

\index{actions!class}
\item[actions class] a class used in conjunction with a grammar 
to perform certain actions when a grammar rule matches 
something in the input data. If a method with the same name 
as a rule in the grammar exists in the actions class, it will 
be called whenever the rule matches.

\end{description}

\section{Exercise: A Grammar for an Arithmetic Calculator}
\label{calculator}
\index{calculator}
\index{calculator!grammar}
\index{grammar!arithmetic calculator}
\index{arithmetic calculator}

The arithmetic calculator presented in Section~\ref{actions_object} 
above is very simplistic. In particular, it can parse simple 
arithmetic expressions composed of two operands separated by 
one infix operator, but not much more than that.

We would like to be able to parse more complicated arithmetic 
expressions. The calculator should also be able to handle:
\begin{itemize}
\item Expressions with several different operators (among the four 
basic arithmetic operators) and multiple operands
\item Standard precedence rules between operators (for example,
multiplications should be performed prior to additions)
\index{precedence}
\item Parentheses to override usual precedence rules
\index{parentheses}
\index{parentheses!overriding precedence rule}
\end{itemize}

These are a few examples of expressions the calculator should 
parse and compute correctly:
\index{parse}
\begin{verbatim}
3 + 4 + 5;
3 + 4 * 5;   # result should be 23
(3 + 4) * 5; # result should be 35 
\end{verbatim}

\begin{exercise}
Your mission, \verb'[Dan|Jim]', should you choose to accept it, 
is to write such a grammar. As usual, should you fail, the 
Government shall deny any knowledge of your actions class.
\index{actions!class}

There are many possible ways to accomplish this; the solution 
presented in Section~\ref{sol_calculator} is only one of them.
\end{exercise}

